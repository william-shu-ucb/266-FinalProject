{
  "best_global_step": 33523,
  "best_metric": 0.9911138842868515,
  "best_model_checkpoint": "/content/drive/MyDrive/MIDS/266/FinalProject/Model/deberta-post-v3-base/checkpoints/checkpoint-33523",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 33523,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0014915132893834084,
      "grad_norm": 1.7134647369384766,
      "learning_rate": 1.9970766339528087e-05,
      "loss": 0.6949,
      "step": 50
    },
    {
      "epoch": 0.0029830265787668168,
      "grad_norm": 13.928990364074707,
      "learning_rate": 1.9940936073740418e-05,
      "loss": 0.5343,
      "step": 100
    },
    {
      "epoch": 0.004474539868150225,
      "grad_norm": 5.911137580871582,
      "learning_rate": 1.991110580795275e-05,
      "loss": 0.277,
      "step": 150
    },
    {
      "epoch": 0.0059660531575336335,
      "grad_norm": 3.436915874481201,
      "learning_rate": 1.9881275542165082e-05,
      "loss": 0.3957,
      "step": 200
    },
    {
      "epoch": 0.007457566446917042,
      "grad_norm": 24.770244598388672,
      "learning_rate": 1.9851445276377416e-05,
      "loss": 0.174,
      "step": 250
    },
    {
      "epoch": 0.00894907973630045,
      "grad_norm": 0.12684379518032074,
      "learning_rate": 1.9821615010589746e-05,
      "loss": 0.1955,
      "step": 300
    },
    {
      "epoch": 0.01044059302568386,
      "grad_norm": 0.04943668097257614,
      "learning_rate": 1.979178474480208e-05,
      "loss": 0.1168,
      "step": 350
    },
    {
      "epoch": 0.011932106315067267,
      "grad_norm": 33.33258056640625,
      "learning_rate": 1.976195447901441e-05,
      "loss": 0.123,
      "step": 400
    },
    {
      "epoch": 0.013423619604450676,
      "grad_norm": 1.0220422744750977,
      "learning_rate": 1.973212421322674e-05,
      "loss": 0.1544,
      "step": 450
    },
    {
      "epoch": 0.014915132893834084,
      "grad_norm": 5.898775100708008,
      "learning_rate": 1.9702293947439074e-05,
      "loss": 0.1811,
      "step": 500
    },
    {
      "epoch": 0.016406646183217494,
      "grad_norm": 21.238317489624023,
      "learning_rate": 1.9672463681651405e-05,
      "loss": 0.1109,
      "step": 550
    },
    {
      "epoch": 0.0178981594726009,
      "grad_norm": 0.060144100338220596,
      "learning_rate": 1.9642633415863735e-05,
      "loss": 0.1283,
      "step": 600
    },
    {
      "epoch": 0.01938967276198431,
      "grad_norm": 46.98396301269531,
      "learning_rate": 1.961280315007607e-05,
      "loss": 0.1129,
      "step": 650
    },
    {
      "epoch": 0.02088118605136772,
      "grad_norm": 12.507681846618652,
      "learning_rate": 1.95829728842884e-05,
      "loss": 0.0805,
      "step": 700
    },
    {
      "epoch": 0.022372699340751125,
      "grad_norm": 14.383275985717773,
      "learning_rate": 1.9553142618500733e-05,
      "loss": 0.195,
      "step": 750
    },
    {
      "epoch": 0.023864212630134534,
      "grad_norm": 42.374759674072266,
      "learning_rate": 1.9523312352713064e-05,
      "loss": 0.1363,
      "step": 800
    },
    {
      "epoch": 0.025355725919517944,
      "grad_norm": 0.09645909070968628,
      "learning_rate": 1.9493482086925397e-05,
      "loss": 0.1279,
      "step": 850
    },
    {
      "epoch": 0.026847239208901353,
      "grad_norm": 0.15776437520980835,
      "learning_rate": 1.9463651821137728e-05,
      "loss": 0.185,
      "step": 900
    },
    {
      "epoch": 0.02833875249828476,
      "grad_norm": 0.01589534990489483,
      "learning_rate": 1.9433821555350058e-05,
      "loss": 0.0694,
      "step": 950
    },
    {
      "epoch": 0.02983026578766817,
      "grad_norm": 1.4959378242492676,
      "learning_rate": 1.9403991289562392e-05,
      "loss": 0.1254,
      "step": 1000
    },
    {
      "epoch": 0.031321779077051574,
      "grad_norm": 0.045289721339941025,
      "learning_rate": 1.9374161023774722e-05,
      "loss": 0.1085,
      "step": 1050
    },
    {
      "epoch": 0.03281329236643499,
      "grad_norm": 0.04265708103775978,
      "learning_rate": 1.9344330757987056e-05,
      "loss": 0.112,
      "step": 1100
    },
    {
      "epoch": 0.03430480565581839,
      "grad_norm": 9.892731666564941,
      "learning_rate": 1.9314500492199386e-05,
      "loss": 0.1039,
      "step": 1150
    },
    {
      "epoch": 0.0357963189452018,
      "grad_norm": 0.11856739223003387,
      "learning_rate": 1.928467022641172e-05,
      "loss": 0.1267,
      "step": 1200
    },
    {
      "epoch": 0.03728783223458521,
      "grad_norm": 61.405914306640625,
      "learning_rate": 1.925483996062405e-05,
      "loss": 0.1903,
      "step": 1250
    },
    {
      "epoch": 0.03877934552396862,
      "grad_norm": 4.132974147796631,
      "learning_rate": 1.9225009694836384e-05,
      "loss": 0.1396,
      "step": 1300
    },
    {
      "epoch": 0.040270858813352024,
      "grad_norm": 0.05352756381034851,
      "learning_rate": 1.9195179429048715e-05,
      "loss": 0.1282,
      "step": 1350
    },
    {
      "epoch": 0.04176237210273544,
      "grad_norm": 11.40602970123291,
      "learning_rate": 1.9165349163261045e-05,
      "loss": 0.0922,
      "step": 1400
    },
    {
      "epoch": 0.04325388539211884,
      "grad_norm": 21.98441505432129,
      "learning_rate": 1.913551889747338e-05,
      "loss": 0.1972,
      "step": 1450
    },
    {
      "epoch": 0.04474539868150225,
      "grad_norm": 53.605552673339844,
      "learning_rate": 1.910568863168571e-05,
      "loss": 0.0711,
      "step": 1500
    },
    {
      "epoch": 0.04623691197088566,
      "grad_norm": 15.573564529418945,
      "learning_rate": 1.907585836589804e-05,
      "loss": 0.1224,
      "step": 1550
    },
    {
      "epoch": 0.04772842526026907,
      "grad_norm": 43.08479309082031,
      "learning_rate": 1.9046028100110374e-05,
      "loss": 0.099,
      "step": 1600
    },
    {
      "epoch": 0.049219938549652474,
      "grad_norm": 0.059692464768886566,
      "learning_rate": 1.9016197834322704e-05,
      "loss": 0.1018,
      "step": 1650
    },
    {
      "epoch": 0.05071145183903589,
      "grad_norm": 0.024671101942658424,
      "learning_rate": 1.8986367568535038e-05,
      "loss": 0.0905,
      "step": 1700
    },
    {
      "epoch": 0.05220296512841929,
      "grad_norm": 0.013697308488190174,
      "learning_rate": 1.8956537302747368e-05,
      "loss": 0.0762,
      "step": 1750
    },
    {
      "epoch": 0.053694478417802706,
      "grad_norm": 53.09366226196289,
      "learning_rate": 1.8926707036959702e-05,
      "loss": 0.0625,
      "step": 1800
    },
    {
      "epoch": 0.05518599170718611,
      "grad_norm": 0.12565065920352936,
      "learning_rate": 1.8896876771172032e-05,
      "loss": 0.0955,
      "step": 1850
    },
    {
      "epoch": 0.05667750499656952,
      "grad_norm": 0.05255134403705597,
      "learning_rate": 1.8867046505384366e-05,
      "loss": 0.0768,
      "step": 1900
    },
    {
      "epoch": 0.05816901828595293,
      "grad_norm": 0.018281269818544388,
      "learning_rate": 1.8837216239596697e-05,
      "loss": 0.0851,
      "step": 1950
    },
    {
      "epoch": 0.05966053157533634,
      "grad_norm": 0.2462582290172577,
      "learning_rate": 1.880738597380903e-05,
      "loss": 0.1025,
      "step": 2000
    },
    {
      "epoch": 0.06115204486471974,
      "grad_norm": 30.082683563232422,
      "learning_rate": 1.877755570802136e-05,
      "loss": 0.1051,
      "step": 2050
    },
    {
      "epoch": 0.06264355815410315,
      "grad_norm": 0.06190785393118858,
      "learning_rate": 1.874772544223369e-05,
      "loss": 0.084,
      "step": 2100
    },
    {
      "epoch": 0.06413507144348655,
      "grad_norm": 0.06163206323981285,
      "learning_rate": 1.8717895176446025e-05,
      "loss": 0.0792,
      "step": 2150
    },
    {
      "epoch": 0.06562658473286997,
      "grad_norm": 2.080989360809326,
      "learning_rate": 1.8688064910658355e-05,
      "loss": 0.1116,
      "step": 2200
    },
    {
      "epoch": 0.06711809802225338,
      "grad_norm": 0.030219970270991325,
      "learning_rate": 1.865823464487069e-05,
      "loss": 0.185,
      "step": 2250
    },
    {
      "epoch": 0.06860961131163679,
      "grad_norm": 0.0826275572180748,
      "learning_rate": 1.862840437908302e-05,
      "loss": 0.1226,
      "step": 2300
    },
    {
      "epoch": 0.07010112460102019,
      "grad_norm": 0.018509676679968834,
      "learning_rate": 1.859857411329535e-05,
      "loss": 0.0823,
      "step": 2350
    },
    {
      "epoch": 0.0715926378904036,
      "grad_norm": 0.13646870851516724,
      "learning_rate": 1.856874384750768e-05,
      "loss": 0.0654,
      "step": 2400
    },
    {
      "epoch": 0.07308415117978702,
      "grad_norm": 0.10510580986738205,
      "learning_rate": 1.8538913581720014e-05,
      "loss": 0.0878,
      "step": 2450
    },
    {
      "epoch": 0.07457566446917042,
      "grad_norm": 0.026222655549645424,
      "learning_rate": 1.8509083315932345e-05,
      "loss": 0.1061,
      "step": 2500
    },
    {
      "epoch": 0.07606717775855383,
      "grad_norm": 0.40105748176574707,
      "learning_rate": 1.8479253050144678e-05,
      "loss": 0.1108,
      "step": 2550
    },
    {
      "epoch": 0.07755869104793724,
      "grad_norm": 0.00638616643846035,
      "learning_rate": 1.844942278435701e-05,
      "loss": 0.0661,
      "step": 2600
    },
    {
      "epoch": 0.07905020433732064,
      "grad_norm": 0.04933125153183937,
      "learning_rate": 1.8419592518569342e-05,
      "loss": 0.09,
      "step": 2650
    },
    {
      "epoch": 0.08054171762670405,
      "grad_norm": 0.027270231395959854,
      "learning_rate": 1.8389762252781673e-05,
      "loss": 0.1386,
      "step": 2700
    },
    {
      "epoch": 0.08203323091608747,
      "grad_norm": 0.07252652198076248,
      "learning_rate": 1.8359931986994007e-05,
      "loss": 0.0945,
      "step": 2750
    },
    {
      "epoch": 0.08352474420547087,
      "grad_norm": 0.3954627215862274,
      "learning_rate": 1.8330101721206337e-05,
      "loss": 0.0605,
      "step": 2800
    },
    {
      "epoch": 0.08501625749485428,
      "grad_norm": 2.8215761184692383,
      "learning_rate": 1.830027145541867e-05,
      "loss": 0.1195,
      "step": 2850
    },
    {
      "epoch": 0.08650777078423769,
      "grad_norm": 11.36191463470459,
      "learning_rate": 1.8270441189631e-05,
      "loss": 0.0911,
      "step": 2900
    },
    {
      "epoch": 0.08799928407362109,
      "grad_norm": 0.04872092977166176,
      "learning_rate": 1.8240610923843335e-05,
      "loss": 0.0602,
      "step": 2950
    },
    {
      "epoch": 0.0894907973630045,
      "grad_norm": 39.843109130859375,
      "learning_rate": 1.8210780658055665e-05,
      "loss": 0.0616,
      "step": 3000
    },
    {
      "epoch": 0.09098231065238792,
      "grad_norm": 6.559559345245361,
      "learning_rate": 1.8180950392267996e-05,
      "loss": 0.0994,
      "step": 3050
    },
    {
      "epoch": 0.09247382394177132,
      "grad_norm": 0.0670928806066513,
      "learning_rate": 1.815112012648033e-05,
      "loss": 0.0938,
      "step": 3100
    },
    {
      "epoch": 0.09396533723115473,
      "grad_norm": 2.167491912841797,
      "learning_rate": 1.812128986069266e-05,
      "loss": 0.0916,
      "step": 3150
    },
    {
      "epoch": 0.09545685052053814,
      "grad_norm": 14.566465377807617,
      "learning_rate": 1.809145959490499e-05,
      "loss": 0.0968,
      "step": 3200
    },
    {
      "epoch": 0.09694836380992154,
      "grad_norm": 0.057340119034051895,
      "learning_rate": 1.8061629329117324e-05,
      "loss": 0.0742,
      "step": 3250
    },
    {
      "epoch": 0.09843987709930495,
      "grad_norm": 0.038693107664585114,
      "learning_rate": 1.8031799063329655e-05,
      "loss": 0.0458,
      "step": 3300
    },
    {
      "epoch": 0.09993139038868837,
      "grad_norm": 0.024944566190242767,
      "learning_rate": 1.8001968797541985e-05,
      "loss": 0.0819,
      "step": 3350
    },
    {
      "epoch": 0.10142290367807177,
      "grad_norm": 22.45223617553711,
      "learning_rate": 1.797213853175432e-05,
      "loss": 0.0751,
      "step": 3400
    },
    {
      "epoch": 0.10291441696745518,
      "grad_norm": 0.044826433062553406,
      "learning_rate": 1.794230826596665e-05,
      "loss": 0.0773,
      "step": 3450
    },
    {
      "epoch": 0.10440593025683859,
      "grad_norm": 10.591482162475586,
      "learning_rate": 1.7912478000178983e-05,
      "loss": 0.0504,
      "step": 3500
    },
    {
      "epoch": 0.10589744354622199,
      "grad_norm": 0.14666621387004852,
      "learning_rate": 1.7882647734391313e-05,
      "loss": 0.0916,
      "step": 3550
    },
    {
      "epoch": 0.10738895683560541,
      "grad_norm": 0.05354384705424309,
      "learning_rate": 1.7852817468603647e-05,
      "loss": 0.1102,
      "step": 3600
    },
    {
      "epoch": 0.10888047012498882,
      "grad_norm": 0.0487838052213192,
      "learning_rate": 1.7822987202815978e-05,
      "loss": 0.0711,
      "step": 3650
    },
    {
      "epoch": 0.11037198341437222,
      "grad_norm": 0.17057333886623383,
      "learning_rate": 1.779315693702831e-05,
      "loss": 0.0707,
      "step": 3700
    },
    {
      "epoch": 0.11186349670375563,
      "grad_norm": 0.5623340010643005,
      "learning_rate": 1.7763326671240642e-05,
      "loss": 0.0936,
      "step": 3750
    },
    {
      "epoch": 0.11335500999313904,
      "grad_norm": 0.3910791575908661,
      "learning_rate": 1.7733496405452976e-05,
      "loss": 0.1162,
      "step": 3800
    },
    {
      "epoch": 0.11484652328252244,
      "grad_norm": 0.018978452309966087,
      "learning_rate": 1.7703666139665306e-05,
      "loss": 0.0819,
      "step": 3850
    },
    {
      "epoch": 0.11633803657190586,
      "grad_norm": 0.12706957757472992,
      "learning_rate": 1.767383587387764e-05,
      "loss": 0.0643,
      "step": 3900
    },
    {
      "epoch": 0.11782954986128927,
      "grad_norm": 0.03665986284613609,
      "learning_rate": 1.764400560808997e-05,
      "loss": 0.0879,
      "step": 3950
    },
    {
      "epoch": 0.11932106315067267,
      "grad_norm": 0.021057292819023132,
      "learning_rate": 1.76141753423023e-05,
      "loss": 0.0652,
      "step": 4000
    },
    {
      "epoch": 0.12081257644005608,
      "grad_norm": 0.012143081054091454,
      "learning_rate": 1.7584345076514634e-05,
      "loss": 0.0604,
      "step": 4050
    },
    {
      "epoch": 0.12230408972943949,
      "grad_norm": 0.0917249247431755,
      "learning_rate": 1.7554514810726965e-05,
      "loss": 0.0827,
      "step": 4100
    },
    {
      "epoch": 0.12379560301882289,
      "grad_norm": 15.041560173034668,
      "learning_rate": 1.7524684544939295e-05,
      "loss": 0.0578,
      "step": 4150
    },
    {
      "epoch": 0.1252871163082063,
      "grad_norm": 11.462663650512695,
      "learning_rate": 1.749485427915163e-05,
      "loss": 0.0904,
      "step": 4200
    },
    {
      "epoch": 0.1267786295975897,
      "grad_norm": 39.240386962890625,
      "learning_rate": 1.746502401336396e-05,
      "loss": 0.0758,
      "step": 4250
    },
    {
      "epoch": 0.1282701428869731,
      "grad_norm": 0.04350380599498749,
      "learning_rate": 1.7435193747576293e-05,
      "loss": 0.0899,
      "step": 4300
    },
    {
      "epoch": 0.12976165617635654,
      "grad_norm": 0.014675813727080822,
      "learning_rate": 1.7405363481788623e-05,
      "loss": 0.0633,
      "step": 4350
    },
    {
      "epoch": 0.13125316946573995,
      "grad_norm": 0.09747245907783508,
      "learning_rate": 1.7375533216000954e-05,
      "loss": 0.102,
      "step": 4400
    },
    {
      "epoch": 0.13274468275512336,
      "grad_norm": 0.0252754557877779,
      "learning_rate": 1.7345702950213288e-05,
      "loss": 0.0931,
      "step": 4450
    },
    {
      "epoch": 0.13423619604450676,
      "grad_norm": 8.258482933044434,
      "learning_rate": 1.7315872684425618e-05,
      "loss": 0.0472,
      "step": 4500
    },
    {
      "epoch": 0.13572770933389017,
      "grad_norm": 0.03259336203336716,
      "learning_rate": 1.7286042418637952e-05,
      "loss": 0.069,
      "step": 4550
    },
    {
      "epoch": 0.13721922262327357,
      "grad_norm": 0.024550389498472214,
      "learning_rate": 1.7256212152850282e-05,
      "loss": 0.0756,
      "step": 4600
    },
    {
      "epoch": 0.13871073591265698,
      "grad_norm": 0.19832472503185272,
      "learning_rate": 1.7226381887062616e-05,
      "loss": 0.0861,
      "step": 4650
    },
    {
      "epoch": 0.14020224920204039,
      "grad_norm": 38.09758377075195,
      "learning_rate": 1.7196551621274946e-05,
      "loss": 0.0839,
      "step": 4700
    },
    {
      "epoch": 0.1416937624914238,
      "grad_norm": 16.064428329467773,
      "learning_rate": 1.716672135548728e-05,
      "loss": 0.0748,
      "step": 4750
    },
    {
      "epoch": 0.1431852757808072,
      "grad_norm": 1.6505142450332642,
      "learning_rate": 1.713689108969961e-05,
      "loss": 0.0758,
      "step": 4800
    },
    {
      "epoch": 0.1446767890701906,
      "grad_norm": 0.10418020933866501,
      "learning_rate": 1.7107060823911944e-05,
      "loss": 0.057,
      "step": 4850
    },
    {
      "epoch": 0.14616830235957404,
      "grad_norm": 16.66493034362793,
      "learning_rate": 1.7077230558124275e-05,
      "loss": 0.1227,
      "step": 4900
    },
    {
      "epoch": 0.14765981564895744,
      "grad_norm": 0.0702478364109993,
      "learning_rate": 1.7047400292336605e-05,
      "loss": 0.084,
      "step": 4950
    },
    {
      "epoch": 0.14915132893834085,
      "grad_norm": 3.464179277420044,
      "learning_rate": 1.701757002654894e-05,
      "loss": 0.1228,
      "step": 5000
    },
    {
      "epoch": 0.15064284222772426,
      "grad_norm": 0.02700040303170681,
      "learning_rate": 1.698773976076127e-05,
      "loss": 0.0735,
      "step": 5050
    },
    {
      "epoch": 0.15213435551710766,
      "grad_norm": 0.10020891577005386,
      "learning_rate": 1.69579094949736e-05,
      "loss": 0.0853,
      "step": 5100
    },
    {
      "epoch": 0.15362586880649107,
      "grad_norm": 0.06850793957710266,
      "learning_rate": 1.6928079229185934e-05,
      "loss": 0.0682,
      "step": 5150
    },
    {
      "epoch": 0.15511738209587447,
      "grad_norm": 0.21611052751541138,
      "learning_rate": 1.6898248963398264e-05,
      "loss": 0.0572,
      "step": 5200
    },
    {
      "epoch": 0.15660889538525788,
      "grad_norm": 0.008149342611432076,
      "learning_rate": 1.6868418697610598e-05,
      "loss": 0.0455,
      "step": 5250
    },
    {
      "epoch": 0.15810040867464129,
      "grad_norm": 0.02050969935953617,
      "learning_rate": 1.6838588431822928e-05,
      "loss": 0.0772,
      "step": 5300
    },
    {
      "epoch": 0.1595919219640247,
      "grad_norm": 0.025869380682706833,
      "learning_rate": 1.6808758166035262e-05,
      "loss": 0.0862,
      "step": 5350
    },
    {
      "epoch": 0.1610834352534081,
      "grad_norm": 0.006190579850226641,
      "learning_rate": 1.6778927900247592e-05,
      "loss": 0.0455,
      "step": 5400
    },
    {
      "epoch": 0.1625749485427915,
      "grad_norm": 0.007050368934869766,
      "learning_rate": 1.6749097634459926e-05,
      "loss": 0.0714,
      "step": 5450
    },
    {
      "epoch": 0.16406646183217494,
      "grad_norm": 0.05035867914557457,
      "learning_rate": 1.6719267368672257e-05,
      "loss": 0.0438,
      "step": 5500
    },
    {
      "epoch": 0.16555797512155834,
      "grad_norm": 0.7116193175315857,
      "learning_rate": 1.6689437102884587e-05,
      "loss": 0.0787,
      "step": 5550
    },
    {
      "epoch": 0.16704948841094175,
      "grad_norm": 0.09860306978225708,
      "learning_rate": 1.665960683709692e-05,
      "loss": 0.0552,
      "step": 5600
    },
    {
      "epoch": 0.16854100170032515,
      "grad_norm": 0.014606657437980175,
      "learning_rate": 1.662977657130925e-05,
      "loss": 0.068,
      "step": 5650
    },
    {
      "epoch": 0.17003251498970856,
      "grad_norm": 0.015306147746741772,
      "learning_rate": 1.6599946305521585e-05,
      "loss": 0.0355,
      "step": 5700
    },
    {
      "epoch": 0.17152402827909197,
      "grad_norm": 29.98319435119629,
      "learning_rate": 1.6570116039733915e-05,
      "loss": 0.0937,
      "step": 5750
    },
    {
      "epoch": 0.17301554156847537,
      "grad_norm": 0.014207984320819378,
      "learning_rate": 1.654028577394625e-05,
      "loss": 0.0686,
      "step": 5800
    },
    {
      "epoch": 0.17450705485785878,
      "grad_norm": 0.02243776060640812,
      "learning_rate": 1.651045550815858e-05,
      "loss": 0.1047,
      "step": 5850
    },
    {
      "epoch": 0.17599856814724218,
      "grad_norm": 0.14039063453674316,
      "learning_rate": 1.648062524237091e-05,
      "loss": 0.0726,
      "step": 5900
    },
    {
      "epoch": 0.1774900814366256,
      "grad_norm": 0.009658296592533588,
      "learning_rate": 1.645079497658324e-05,
      "loss": 0.0263,
      "step": 5950
    },
    {
      "epoch": 0.178981594726009,
      "grad_norm": 0.1143338680267334,
      "learning_rate": 1.6420964710795574e-05,
      "loss": 0.0886,
      "step": 6000
    },
    {
      "epoch": 0.18047310801539243,
      "grad_norm": 12.832101821899414,
      "learning_rate": 1.6391134445007904e-05,
      "loss": 0.0349,
      "step": 6050
    },
    {
      "epoch": 0.18196462130477584,
      "grad_norm": 0.10112037509679794,
      "learning_rate": 1.6361304179220238e-05,
      "loss": 0.0652,
      "step": 6100
    },
    {
      "epoch": 0.18345613459415924,
      "grad_norm": 16.74302864074707,
      "learning_rate": 1.633147391343257e-05,
      "loss": 0.0841,
      "step": 6150
    },
    {
      "epoch": 0.18494764788354265,
      "grad_norm": 0.2116371989250183,
      "learning_rate": 1.6301643647644902e-05,
      "loss": 0.0601,
      "step": 6200
    },
    {
      "epoch": 0.18643916117292605,
      "grad_norm": 0.361479789018631,
      "learning_rate": 1.6271813381857233e-05,
      "loss": 0.0724,
      "step": 6250
    },
    {
      "epoch": 0.18793067446230946,
      "grad_norm": 0.021632734686136246,
      "learning_rate": 1.6241983116069567e-05,
      "loss": 0.0581,
      "step": 6300
    },
    {
      "epoch": 0.18942218775169287,
      "grad_norm": 0.09974134713411331,
      "learning_rate": 1.6212152850281897e-05,
      "loss": 0.0961,
      "step": 6350
    },
    {
      "epoch": 0.19091370104107627,
      "grad_norm": 0.007267926353961229,
      "learning_rate": 1.618232258449423e-05,
      "loss": 0.0468,
      "step": 6400
    },
    {
      "epoch": 0.19240521433045968,
      "grad_norm": 0.3494252860546112,
      "learning_rate": 1.615249231870656e-05,
      "loss": 0.0709,
      "step": 6450
    },
    {
      "epoch": 0.19389672761984308,
      "grad_norm": 0.007843461818993092,
      "learning_rate": 1.6122662052918895e-05,
      "loss": 0.0661,
      "step": 6500
    },
    {
      "epoch": 0.1953882409092265,
      "grad_norm": 13.301590919494629,
      "learning_rate": 1.6092831787131225e-05,
      "loss": 0.0361,
      "step": 6550
    },
    {
      "epoch": 0.1968797541986099,
      "grad_norm": 0.07449141144752502,
      "learning_rate": 1.6063001521343556e-05,
      "loss": 0.0773,
      "step": 6600
    },
    {
      "epoch": 0.19837126748799333,
      "grad_norm": 10.985787391662598,
      "learning_rate": 1.603317125555589e-05,
      "loss": 0.0751,
      "step": 6650
    },
    {
      "epoch": 0.19986278077737674,
      "grad_norm": 15.845161437988281,
      "learning_rate": 1.600334098976822e-05,
      "loss": 0.0711,
      "step": 6700
    },
    {
      "epoch": 0.20135429406676014,
      "grad_norm": 0.19796821475028992,
      "learning_rate": 1.597351072398055e-05,
      "loss": 0.0352,
      "step": 6750
    },
    {
      "epoch": 0.20284580735614355,
      "grad_norm": 22.162315368652344,
      "learning_rate": 1.5943680458192884e-05,
      "loss": 0.119,
      "step": 6800
    },
    {
      "epoch": 0.20433732064552695,
      "grad_norm": 0.00589025067165494,
      "learning_rate": 1.5913850192405215e-05,
      "loss": 0.0526,
      "step": 6850
    },
    {
      "epoch": 0.20582883393491036,
      "grad_norm": 0.014847326092422009,
      "learning_rate": 1.5884019926617545e-05,
      "loss": 0.053,
      "step": 6900
    },
    {
      "epoch": 0.20732034722429377,
      "grad_norm": 0.9594576358795166,
      "learning_rate": 1.585418966082988e-05,
      "loss": 0.0886,
      "step": 6950
    },
    {
      "epoch": 0.20881186051367717,
      "grad_norm": 2.2925965785980225,
      "learning_rate": 1.582435939504221e-05,
      "loss": 0.0773,
      "step": 7000
    },
    {
      "epoch": 0.21030337380306058,
      "grad_norm": 26.89405632019043,
      "learning_rate": 1.5794529129254543e-05,
      "loss": 0.0723,
      "step": 7050
    },
    {
      "epoch": 0.21179488709244398,
      "grad_norm": 0.011692571453750134,
      "learning_rate": 1.5764698863466873e-05,
      "loss": 0.0506,
      "step": 7100
    },
    {
      "epoch": 0.2132864003818274,
      "grad_norm": 0.02642465941607952,
      "learning_rate": 1.5734868597679207e-05,
      "loss": 0.0584,
      "step": 7150
    },
    {
      "epoch": 0.21477791367121082,
      "grad_norm": 17.705732345581055,
      "learning_rate": 1.5705038331891538e-05,
      "loss": 0.1048,
      "step": 7200
    },
    {
      "epoch": 0.21626942696059423,
      "grad_norm": 0.041531600058078766,
      "learning_rate": 1.567520806610387e-05,
      "loss": 0.0698,
      "step": 7250
    },
    {
      "epoch": 0.21776094024997764,
      "grad_norm": 0.17046864330768585,
      "learning_rate": 1.5645377800316202e-05,
      "loss": 0.1162,
      "step": 7300
    },
    {
      "epoch": 0.21925245353936104,
      "grad_norm": 10.325063705444336,
      "learning_rate": 1.5615547534528536e-05,
      "loss": 0.0876,
      "step": 7350
    },
    {
      "epoch": 0.22074396682874445,
      "grad_norm": 1.0261203050613403,
      "learning_rate": 1.5585717268740866e-05,
      "loss": 0.0492,
      "step": 7400
    },
    {
      "epoch": 0.22223548011812785,
      "grad_norm": 0.007751553785055876,
      "learning_rate": 1.55558870029532e-05,
      "loss": 0.0803,
      "step": 7450
    },
    {
      "epoch": 0.22372699340751126,
      "grad_norm": 0.1926114708185196,
      "learning_rate": 1.552605673716553e-05,
      "loss": 0.0374,
      "step": 7500
    },
    {
      "epoch": 0.22521850669689467,
      "grad_norm": 0.11895208805799484,
      "learning_rate": 1.549622647137786e-05,
      "loss": 0.0995,
      "step": 7550
    },
    {
      "epoch": 0.22671001998627807,
      "grad_norm": 0.09437728673219681,
      "learning_rate": 1.5466396205590194e-05,
      "loss": 0.111,
      "step": 7600
    },
    {
      "epoch": 0.22820153327566148,
      "grad_norm": 0.463085800409317,
      "learning_rate": 1.5436565939802525e-05,
      "loss": 0.0928,
      "step": 7650
    },
    {
      "epoch": 0.22969304656504488,
      "grad_norm": 0.003065200522542,
      "learning_rate": 1.5406735674014855e-05,
      "loss": 0.0176,
      "step": 7700
    },
    {
      "epoch": 0.2311845598544283,
      "grad_norm": 0.027689103037118912,
      "learning_rate": 1.537690540822719e-05,
      "loss": 0.0767,
      "step": 7750
    },
    {
      "epoch": 0.23267607314381172,
      "grad_norm": 5.391754150390625,
      "learning_rate": 1.534707514243952e-05,
      "loss": 0.0652,
      "step": 7800
    },
    {
      "epoch": 0.23416758643319513,
      "grad_norm": 0.01392044685781002,
      "learning_rate": 1.531724487665185e-05,
      "loss": 0.0403,
      "step": 7850
    },
    {
      "epoch": 0.23565909972257854,
      "grad_norm": 15.2378568649292,
      "learning_rate": 1.5287414610864183e-05,
      "loss": 0.0841,
      "step": 7900
    },
    {
      "epoch": 0.23715061301196194,
      "grad_norm": 0.12063220888376236,
      "learning_rate": 1.5257584345076516e-05,
      "loss": 0.0478,
      "step": 7950
    },
    {
      "epoch": 0.23864212630134535,
      "grad_norm": 7.065927028656006,
      "learning_rate": 1.5227754079288848e-05,
      "loss": 0.097,
      "step": 8000
    },
    {
      "epoch": 0.24013363959072875,
      "grad_norm": 0.03815682977437973,
      "learning_rate": 1.5197923813501178e-05,
      "loss": 0.0486,
      "step": 8050
    },
    {
      "epoch": 0.24162515288011216,
      "grad_norm": 0.06706909835338593,
      "learning_rate": 1.5168093547713512e-05,
      "loss": 0.0996,
      "step": 8100
    },
    {
      "epoch": 0.24311666616949557,
      "grad_norm": 8.33481502532959,
      "learning_rate": 1.5138263281925842e-05,
      "loss": 0.0396,
      "step": 8150
    },
    {
      "epoch": 0.24460817945887897,
      "grad_norm": 22.09827423095703,
      "learning_rate": 1.5108433016138176e-05,
      "loss": 0.0291,
      "step": 8200
    },
    {
      "epoch": 0.24609969274826238,
      "grad_norm": 0.8218786120414734,
      "learning_rate": 1.5078602750350506e-05,
      "loss": 0.082,
      "step": 8250
    },
    {
      "epoch": 0.24759120603764578,
      "grad_norm": 0.36414387822151184,
      "learning_rate": 1.5048772484562839e-05,
      "loss": 0.0817,
      "step": 8300
    },
    {
      "epoch": 0.24908271932702922,
      "grad_norm": 0.03720339015126228,
      "learning_rate": 1.501894221877517e-05,
      "loss": 0.0694,
      "step": 8350
    },
    {
      "epoch": 0.2505742326164126,
      "grad_norm": 0.100652776658535,
      "learning_rate": 1.4989111952987503e-05,
      "loss": 0.0837,
      "step": 8400
    },
    {
      "epoch": 0.252065745905796,
      "grad_norm": 11.194668769836426,
      "learning_rate": 1.4959281687199833e-05,
      "loss": 0.0448,
      "step": 8450
    },
    {
      "epoch": 0.2535572591951794,
      "grad_norm": 0.009740074165165424,
      "learning_rate": 1.4929451421412167e-05,
      "loss": 0.0767,
      "step": 8500
    },
    {
      "epoch": 0.2550487724845628,
      "grad_norm": 7.2286810874938965,
      "learning_rate": 1.4899621155624497e-05,
      "loss": 0.0726,
      "step": 8550
    },
    {
      "epoch": 0.2565402857739462,
      "grad_norm": 0.030750876292586327,
      "learning_rate": 1.4869790889836831e-05,
      "loss": 0.0715,
      "step": 8600
    },
    {
      "epoch": 0.2580317990633297,
      "grad_norm": 0.5156105756759644,
      "learning_rate": 1.4839960624049161e-05,
      "loss": 0.0474,
      "step": 8650
    },
    {
      "epoch": 0.2595233123527131,
      "grad_norm": 0.00727895786985755,
      "learning_rate": 1.4810130358261494e-05,
      "loss": 0.0193,
      "step": 8700
    },
    {
      "epoch": 0.2610148256420965,
      "grad_norm": 0.020006002858281136,
      "learning_rate": 1.4780300092473826e-05,
      "loss": 0.0575,
      "step": 8750
    },
    {
      "epoch": 0.2625063389314799,
      "grad_norm": 1.1303458213806152,
      "learning_rate": 1.4750469826686158e-05,
      "loss": 0.0433,
      "step": 8800
    },
    {
      "epoch": 0.2639978522208633,
      "grad_norm": 0.2918241024017334,
      "learning_rate": 1.4720639560898488e-05,
      "loss": 0.0609,
      "step": 8850
    },
    {
      "epoch": 0.2654893655102467,
      "grad_norm": 44.44678497314453,
      "learning_rate": 1.4690809295110822e-05,
      "loss": 0.0384,
      "step": 8900
    },
    {
      "epoch": 0.2669808787996301,
      "grad_norm": 0.13996551930904388,
      "learning_rate": 1.4660979029323152e-05,
      "loss": 0.0416,
      "step": 8950
    },
    {
      "epoch": 0.2684723920890135,
      "grad_norm": 1.4367828369140625,
      "learning_rate": 1.4631148763535483e-05,
      "loss": 0.073,
      "step": 9000
    },
    {
      "epoch": 0.26996390537839693,
      "grad_norm": 0.19630208611488342,
      "learning_rate": 1.4601318497747817e-05,
      "loss": 0.068,
      "step": 9050
    },
    {
      "epoch": 0.27145541866778033,
      "grad_norm": 20.262962341308594,
      "learning_rate": 1.4571488231960147e-05,
      "loss": 0.0867,
      "step": 9100
    },
    {
      "epoch": 0.27294693195716374,
      "grad_norm": 0.007321149576455355,
      "learning_rate": 1.454165796617248e-05,
      "loss": 0.0678,
      "step": 9150
    },
    {
      "epoch": 0.27443844524654715,
      "grad_norm": 20.366527557373047,
      "learning_rate": 1.4511827700384811e-05,
      "loss": 0.0767,
      "step": 9200
    },
    {
      "epoch": 0.27592995853593055,
      "grad_norm": 0.3974836468696594,
      "learning_rate": 1.4481997434597143e-05,
      "loss": 0.0822,
      "step": 9250
    },
    {
      "epoch": 0.27742147182531396,
      "grad_norm": 0.01408794242888689,
      "learning_rate": 1.4452167168809475e-05,
      "loss": 0.0281,
      "step": 9300
    },
    {
      "epoch": 0.27891298511469736,
      "grad_norm": 0.007523881271481514,
      "learning_rate": 1.4422336903021807e-05,
      "loss": 0.0545,
      "step": 9350
    },
    {
      "epoch": 0.28040449840408077,
      "grad_norm": 0.00630177604034543,
      "learning_rate": 1.4392506637234138e-05,
      "loss": 0.0298,
      "step": 9400
    },
    {
      "epoch": 0.2818960116934642,
      "grad_norm": 0.07688422501087189,
      "learning_rate": 1.4362676371446472e-05,
      "loss": 0.0695,
      "step": 9450
    },
    {
      "epoch": 0.2833875249828476,
      "grad_norm": 4.120337963104248,
      "learning_rate": 1.4332846105658802e-05,
      "loss": 0.0661,
      "step": 9500
    },
    {
      "epoch": 0.284879038272231,
      "grad_norm": 0.7870758175849915,
      "learning_rate": 1.4303015839871136e-05,
      "loss": 0.0568,
      "step": 9550
    },
    {
      "epoch": 0.2863705515616144,
      "grad_norm": 0.04458225518465042,
      "learning_rate": 1.4273185574083466e-05,
      "loss": 0.0366,
      "step": 9600
    },
    {
      "epoch": 0.2878620648509978,
      "grad_norm": 0.17294751107692719,
      "learning_rate": 1.4243355308295798e-05,
      "loss": 0.0926,
      "step": 9650
    },
    {
      "epoch": 0.2893535781403812,
      "grad_norm": 0.03521926701068878,
      "learning_rate": 1.4213525042508129e-05,
      "loss": 0.0506,
      "step": 9700
    },
    {
      "epoch": 0.2908450914297646,
      "grad_norm": 0.018519653007388115,
      "learning_rate": 1.4183694776720462e-05,
      "loss": 0.053,
      "step": 9750
    },
    {
      "epoch": 0.2923366047191481,
      "grad_norm": 0.008063866756856441,
      "learning_rate": 1.4153864510932793e-05,
      "loss": 0.0397,
      "step": 9800
    },
    {
      "epoch": 0.2938281180085315,
      "grad_norm": 0.2583816647529602,
      "learning_rate": 1.4124034245145127e-05,
      "loss": 0.0478,
      "step": 9850
    },
    {
      "epoch": 0.2953196312979149,
      "grad_norm": 0.13368502259254456,
      "learning_rate": 1.4094203979357457e-05,
      "loss": 0.0567,
      "step": 9900
    },
    {
      "epoch": 0.2968111445872983,
      "grad_norm": 0.3686794638633728,
      "learning_rate": 1.406437371356979e-05,
      "loss": 0.0705,
      "step": 9950
    },
    {
      "epoch": 0.2983026578766817,
      "grad_norm": 17.917409896850586,
      "learning_rate": 1.4034543447782121e-05,
      "loss": 0.0359,
      "step": 10000
    },
    {
      "epoch": 0.2997941711660651,
      "grad_norm": 0.02183184213936329,
      "learning_rate": 1.4004713181994453e-05,
      "loss": 0.0776,
      "step": 10050
    },
    {
      "epoch": 0.3012856844554485,
      "grad_norm": 0.048731401562690735,
      "learning_rate": 1.3974882916206784e-05,
      "loss": 0.0715,
      "step": 10100
    },
    {
      "epoch": 0.3027771977448319,
      "grad_norm": 0.03934011608362198,
      "learning_rate": 1.3945052650419116e-05,
      "loss": 0.08,
      "step": 10150
    },
    {
      "epoch": 0.3042687110342153,
      "grad_norm": 0.014030053280293941,
      "learning_rate": 1.3915222384631448e-05,
      "loss": 0.0556,
      "step": 10200
    },
    {
      "epoch": 0.30576022432359873,
      "grad_norm": 9.885761260986328,
      "learning_rate": 1.3885392118843778e-05,
      "loss": 0.0673,
      "step": 10250
    },
    {
      "epoch": 0.30725173761298213,
      "grad_norm": 0.036423422396183014,
      "learning_rate": 1.3855561853056112e-05,
      "loss": 0.0497,
      "step": 10300
    },
    {
      "epoch": 0.30874325090236554,
      "grad_norm": 0.1509723663330078,
      "learning_rate": 1.3825731587268442e-05,
      "loss": 0.083,
      "step": 10350
    },
    {
      "epoch": 0.31023476419174895,
      "grad_norm": 0.006902811583131552,
      "learning_rate": 1.3795901321480776e-05,
      "loss": 0.0708,
      "step": 10400
    },
    {
      "epoch": 0.31172627748113235,
      "grad_norm": 0.07231862097978592,
      "learning_rate": 1.3766071055693107e-05,
      "loss": 0.0641,
      "step": 10450
    },
    {
      "epoch": 0.31321779077051576,
      "grad_norm": 0.16817744076251984,
      "learning_rate": 1.3736240789905439e-05,
      "loss": 0.0409,
      "step": 10500
    },
    {
      "epoch": 0.31470930405989916,
      "grad_norm": 0.12229792773723602,
      "learning_rate": 1.3706410524117771e-05,
      "loss": 0.0548,
      "step": 10550
    },
    {
      "epoch": 0.31620081734928257,
      "grad_norm": 0.015258676372468472,
      "learning_rate": 1.3676580258330103e-05,
      "loss": 0.044,
      "step": 10600
    },
    {
      "epoch": 0.317692330638666,
      "grad_norm": 0.0359325185418129,
      "learning_rate": 1.3646749992542433e-05,
      "loss": 0.0406,
      "step": 10650
    },
    {
      "epoch": 0.3191838439280494,
      "grad_norm": 0.19280658662319183,
      "learning_rate": 1.3616919726754767e-05,
      "loss": 0.0376,
      "step": 10700
    },
    {
      "epoch": 0.3206753572174328,
      "grad_norm": 1.33370840549469,
      "learning_rate": 1.3587089460967098e-05,
      "loss": 0.0567,
      "step": 10750
    },
    {
      "epoch": 0.3221668705068162,
      "grad_norm": 0.033731065690517426,
      "learning_rate": 1.3557259195179431e-05,
      "loss": 0.0354,
      "step": 10800
    },
    {
      "epoch": 0.3236583837961996,
      "grad_norm": 0.05015655234456062,
      "learning_rate": 1.3527428929391762e-05,
      "loss": 0.0688,
      "step": 10850
    },
    {
      "epoch": 0.325149897085583,
      "grad_norm": 0.03392460197210312,
      "learning_rate": 1.3497598663604094e-05,
      "loss": 0.0433,
      "step": 10900
    },
    {
      "epoch": 0.32664141037496647,
      "grad_norm": 0.010250349529087543,
      "learning_rate": 1.3467768397816426e-05,
      "loss": 0.0194,
      "step": 10950
    },
    {
      "epoch": 0.3281329236643499,
      "grad_norm": 0.08330485969781876,
      "learning_rate": 1.3437938132028758e-05,
      "loss": 0.0639,
      "step": 11000
    },
    {
      "epoch": 0.3296244369537333,
      "grad_norm": 0.3876703381538391,
      "learning_rate": 1.3408107866241088e-05,
      "loss": 0.0609,
      "step": 11050
    },
    {
      "epoch": 0.3311159502431167,
      "grad_norm": 0.033684104681015015,
      "learning_rate": 1.3378277600453422e-05,
      "loss": 0.0614,
      "step": 11100
    },
    {
      "epoch": 0.3326074635325001,
      "grad_norm": 0.008942540735006332,
      "learning_rate": 1.3348447334665753e-05,
      "loss": 0.084,
      "step": 11150
    },
    {
      "epoch": 0.3340989768218835,
      "grad_norm": 0.08566998690366745,
      "learning_rate": 1.3318617068878086e-05,
      "loss": 0.0379,
      "step": 11200
    },
    {
      "epoch": 0.3355904901112669,
      "grad_norm": 6.174447536468506,
      "learning_rate": 1.3288786803090417e-05,
      "loss": 0.0652,
      "step": 11250
    },
    {
      "epoch": 0.3370820034006503,
      "grad_norm": 0.4507201015949249,
      "learning_rate": 1.3258956537302747e-05,
      "loss": 0.0402,
      "step": 11300
    },
    {
      "epoch": 0.3385735166900337,
      "grad_norm": 0.0063142902217805386,
      "learning_rate": 1.3229126271515081e-05,
      "loss": 0.0581,
      "step": 11350
    },
    {
      "epoch": 0.3400650299794171,
      "grad_norm": 0.08924438059329987,
      "learning_rate": 1.3199296005727411e-05,
      "loss": 0.0059,
      "step": 11400
    },
    {
      "epoch": 0.3415565432688005,
      "grad_norm": 0.042963091284036636,
      "learning_rate": 1.3169465739939743e-05,
      "loss": 0.0277,
      "step": 11450
    },
    {
      "epoch": 0.34304805655818393,
      "grad_norm": 0.0033853843342512846,
      "learning_rate": 1.3139635474152076e-05,
      "loss": 0.0739,
      "step": 11500
    },
    {
      "epoch": 0.34453956984756734,
      "grad_norm": 0.0026166250463575125,
      "learning_rate": 1.3109805208364408e-05,
      "loss": 0.0363,
      "step": 11550
    },
    {
      "epoch": 0.34603108313695075,
      "grad_norm": 0.0038619101978838444,
      "learning_rate": 1.3079974942576738e-05,
      "loss": 0.0709,
      "step": 11600
    },
    {
      "epoch": 0.34752259642633415,
      "grad_norm": 17.569272994995117,
      "learning_rate": 1.3050144676789072e-05,
      "loss": 0.0589,
      "step": 11650
    },
    {
      "epoch": 0.34901410971571756,
      "grad_norm": 0.010457707569003105,
      "learning_rate": 1.3020314411001402e-05,
      "loss": 0.0465,
      "step": 11700
    },
    {
      "epoch": 0.35050562300510096,
      "grad_norm": 0.31370893120765686,
      "learning_rate": 1.2990484145213736e-05,
      "loss": 0.0326,
      "step": 11750
    },
    {
      "epoch": 0.35199713629448437,
      "grad_norm": 10.341259956359863,
      "learning_rate": 1.2960653879426066e-05,
      "loss": 0.0972,
      "step": 11800
    },
    {
      "epoch": 0.3534886495838678,
      "grad_norm": 10.761453628540039,
      "learning_rate": 1.2930823613638398e-05,
      "loss": 0.045,
      "step": 11850
    },
    {
      "epoch": 0.3549801628732512,
      "grad_norm": 0.0036897696554660797,
      "learning_rate": 1.290099334785073e-05,
      "loss": 0.0267,
      "step": 11900
    },
    {
      "epoch": 0.3564716761626346,
      "grad_norm": 0.020033493638038635,
      "learning_rate": 1.2871163082063063e-05,
      "loss": 0.0186,
      "step": 11950
    },
    {
      "epoch": 0.357963189452018,
      "grad_norm": 0.0749417245388031,
      "learning_rate": 1.2841332816275393e-05,
      "loss": 0.0876,
      "step": 12000
    },
    {
      "epoch": 0.3594547027414014,
      "grad_norm": 54.06873321533203,
      "learning_rate": 1.2811502550487727e-05,
      "loss": 0.0744,
      "step": 12050
    },
    {
      "epoch": 0.36094621603078486,
      "grad_norm": 0.8868536949157715,
      "learning_rate": 1.2781672284700057e-05,
      "loss": 0.067,
      "step": 12100
    },
    {
      "epoch": 0.36243772932016827,
      "grad_norm": 0.004784785211086273,
      "learning_rate": 1.2751842018912391e-05,
      "loss": 0.0295,
      "step": 12150
    },
    {
      "epoch": 0.3639292426095517,
      "grad_norm": 4.806403160095215,
      "learning_rate": 1.2722011753124721e-05,
      "loss": 0.0749,
      "step": 12200
    },
    {
      "epoch": 0.3654207558989351,
      "grad_norm": 0.2645527720451355,
      "learning_rate": 1.2692181487337054e-05,
      "loss": 0.0709,
      "step": 12250
    },
    {
      "epoch": 0.3669122691883185,
      "grad_norm": 0.12485858052968979,
      "learning_rate": 1.2662351221549386e-05,
      "loss": 0.0451,
      "step": 12300
    },
    {
      "epoch": 0.3684037824777019,
      "grad_norm": 0.02188505232334137,
      "learning_rate": 1.2632520955761718e-05,
      "loss": 0.042,
      "step": 12350
    },
    {
      "epoch": 0.3698952957670853,
      "grad_norm": 0.04676611348986626,
      "learning_rate": 1.2602690689974048e-05,
      "loss": 0.0753,
      "step": 12400
    },
    {
      "epoch": 0.3713868090564687,
      "grad_norm": 19.558929443359375,
      "learning_rate": 1.257286042418638e-05,
      "loss": 0.0641,
      "step": 12450
    },
    {
      "epoch": 0.3728783223458521,
      "grad_norm": 0.15032725036144257,
      "learning_rate": 1.2543030158398712e-05,
      "loss": 0.057,
      "step": 12500
    },
    {
      "epoch": 0.3743698356352355,
      "grad_norm": 7.347365856170654,
      "learning_rate": 1.2513199892611043e-05,
      "loss": 0.0496,
      "step": 12550
    },
    {
      "epoch": 0.3758613489246189,
      "grad_norm": 0.09532409906387329,
      "learning_rate": 1.2483369626823377e-05,
      "loss": 0.0923,
      "step": 12600
    },
    {
      "epoch": 0.3773528622140023,
      "grad_norm": 0.3754061758518219,
      "learning_rate": 1.2453539361035707e-05,
      "loss": 0.0429,
      "step": 12650
    },
    {
      "epoch": 0.37884437550338573,
      "grad_norm": 0.8048714995384216,
      "learning_rate": 1.242370909524804e-05,
      "loss": 0.0528,
      "step": 12700
    },
    {
      "epoch": 0.38033588879276914,
      "grad_norm": 0.0016668179305270314,
      "learning_rate": 1.2393878829460371e-05,
      "loss": 0.0202,
      "step": 12750
    },
    {
      "epoch": 0.38182740208215254,
      "grad_norm": 8.159608840942383,
      "learning_rate": 1.2364048563672703e-05,
      "loss": 0.0339,
      "step": 12800
    },
    {
      "epoch": 0.38331891537153595,
      "grad_norm": 0.18877725303173065,
      "learning_rate": 1.2334218297885035e-05,
      "loss": 0.0312,
      "step": 12850
    },
    {
      "epoch": 0.38481042866091936,
      "grad_norm": 0.9716647863388062,
      "learning_rate": 1.2304388032097367e-05,
      "loss": 0.0645,
      "step": 12900
    },
    {
      "epoch": 0.38630194195030276,
      "grad_norm": 0.0033603280317038298,
      "learning_rate": 1.2274557766309698e-05,
      "loss": 0.0622,
      "step": 12950
    },
    {
      "epoch": 0.38779345523968617,
      "grad_norm": 0.00831950269639492,
      "learning_rate": 1.2244727500522032e-05,
      "loss": 0.0323,
      "step": 13000
    },
    {
      "epoch": 0.3892849685290696,
      "grad_norm": 0.14013461768627167,
      "learning_rate": 1.2214897234734362e-05,
      "loss": 0.0861,
      "step": 13050
    },
    {
      "epoch": 0.390776481818453,
      "grad_norm": 0.04288066178560257,
      "learning_rate": 1.2185066968946696e-05,
      "loss": 0.0628,
      "step": 13100
    },
    {
      "epoch": 0.3922679951078364,
      "grad_norm": 21.01715850830078,
      "learning_rate": 1.2155236703159026e-05,
      "loss": 0.0483,
      "step": 13150
    },
    {
      "epoch": 0.3937595083972198,
      "grad_norm": 0.009492939338088036,
      "learning_rate": 1.2125406437371358e-05,
      "loss": 0.0306,
      "step": 13200
    },
    {
      "epoch": 0.39525102168660325,
      "grad_norm": 0.010059730149805546,
      "learning_rate": 1.2095576171583689e-05,
      "loss": 0.0762,
      "step": 13250
    },
    {
      "epoch": 0.39674253497598666,
      "grad_norm": 0.012304707430303097,
      "learning_rate": 1.2065745905796022e-05,
      "loss": 0.0362,
      "step": 13300
    },
    {
      "epoch": 0.39823404826537007,
      "grad_norm": 4.746747970581055,
      "learning_rate": 1.2035915640008353e-05,
      "loss": 0.1077,
      "step": 13350
    },
    {
      "epoch": 0.3997255615547535,
      "grad_norm": 0.12468022853136063,
      "learning_rate": 1.2006085374220687e-05,
      "loss": 0.0622,
      "step": 13400
    },
    {
      "epoch": 0.4012170748441369,
      "grad_norm": 0.006701842416077852,
      "learning_rate": 1.1976255108433017e-05,
      "loss": 0.046,
      "step": 13450
    },
    {
      "epoch": 0.4027085881335203,
      "grad_norm": 0.021038301289081573,
      "learning_rate": 1.194642484264535e-05,
      "loss": 0.0683,
      "step": 13500
    },
    {
      "epoch": 0.4042001014229037,
      "grad_norm": 6.757339954376221,
      "learning_rate": 1.1916594576857681e-05,
      "loss": 0.0547,
      "step": 13550
    },
    {
      "epoch": 0.4056916147122871,
      "grad_norm": 0.0455094613134861,
      "learning_rate": 1.1886764311070012e-05,
      "loss": 0.0509,
      "step": 13600
    },
    {
      "epoch": 0.4071831280016705,
      "grad_norm": 2.3776116371154785,
      "learning_rate": 1.1856934045282344e-05,
      "loss": 0.0383,
      "step": 13650
    },
    {
      "epoch": 0.4086746412910539,
      "grad_norm": 0.006166110746562481,
      "learning_rate": 1.1827103779494676e-05,
      "loss": 0.0352,
      "step": 13700
    },
    {
      "epoch": 0.4101661545804373,
      "grad_norm": 0.024299565702676773,
      "learning_rate": 1.1797273513707008e-05,
      "loss": 0.0571,
      "step": 13750
    },
    {
      "epoch": 0.4116576678698207,
      "grad_norm": 0.003231191774830222,
      "learning_rate": 1.1767443247919338e-05,
      "loss": 0.0397,
      "step": 13800
    },
    {
      "epoch": 0.4131491811592041,
      "grad_norm": 0.0038333956617861986,
      "learning_rate": 1.1737612982131672e-05,
      "loss": 0.0724,
      "step": 13850
    },
    {
      "epoch": 0.41464069444858753,
      "grad_norm": 0.14793144166469574,
      "learning_rate": 1.1707782716344002e-05,
      "loss": 0.0679,
      "step": 13900
    },
    {
      "epoch": 0.41613220773797094,
      "grad_norm": 0.01963544636964798,
      "learning_rate": 1.1677952450556336e-05,
      "loss": 0.0587,
      "step": 13950
    },
    {
      "epoch": 0.41762372102735434,
      "grad_norm": 0.24784600734710693,
      "learning_rate": 1.1648122184768667e-05,
      "loss": 0.0314,
      "step": 14000
    },
    {
      "epoch": 0.41911523431673775,
      "grad_norm": 0.003953000530600548,
      "learning_rate": 1.1618291918980999e-05,
      "loss": 0.0352,
      "step": 14050
    },
    {
      "epoch": 0.42060674760612116,
      "grad_norm": 0.008759954012930393,
      "learning_rate": 1.158846165319333e-05,
      "loss": 0.0472,
      "step": 14100
    },
    {
      "epoch": 0.42209826089550456,
      "grad_norm": 0.09241043031215668,
      "learning_rate": 1.1558631387405663e-05,
      "loss": 0.0895,
      "step": 14150
    },
    {
      "epoch": 0.42358977418488797,
      "grad_norm": 15.686907768249512,
      "learning_rate": 1.1528801121617993e-05,
      "loss": 0.0384,
      "step": 14200
    },
    {
      "epoch": 0.4250812874742714,
      "grad_norm": 0.014582916162908077,
      "learning_rate": 1.1498970855830327e-05,
      "loss": 0.0906,
      "step": 14250
    },
    {
      "epoch": 0.4265728007636548,
      "grad_norm": 0.37715744972229004,
      "learning_rate": 1.1469140590042658e-05,
      "loss": 0.0863,
      "step": 14300
    },
    {
      "epoch": 0.4280643140530382,
      "grad_norm": 16.109554290771484,
      "learning_rate": 1.1439310324254991e-05,
      "loss": 0.0329,
      "step": 14350
    },
    {
      "epoch": 0.42955582734242165,
      "grad_norm": 0.004060080740600824,
      "learning_rate": 1.1409480058467322e-05,
      "loss": 0.0342,
      "step": 14400
    },
    {
      "epoch": 0.43104734063180505,
      "grad_norm": 6.717556476593018,
      "learning_rate": 1.1379649792679654e-05,
      "loss": 0.0547,
      "step": 14450
    },
    {
      "epoch": 0.43253885392118846,
      "grad_norm": 0.0056820516474545,
      "learning_rate": 1.1349819526891986e-05,
      "loss": 0.0185,
      "step": 14500
    },
    {
      "epoch": 0.43403036721057187,
      "grad_norm": 0.0717538595199585,
      "learning_rate": 1.1319989261104318e-05,
      "loss": 0.0711,
      "step": 14550
    },
    {
      "epoch": 0.43552188049995527,
      "grad_norm": 0.0829668939113617,
      "learning_rate": 1.1290158995316648e-05,
      "loss": 0.0469,
      "step": 14600
    },
    {
      "epoch": 0.4370133937893387,
      "grad_norm": 11.767829895019531,
      "learning_rate": 1.1260328729528982e-05,
      "loss": 0.0844,
      "step": 14650
    },
    {
      "epoch": 0.4385049070787221,
      "grad_norm": 9.691061019897461,
      "learning_rate": 1.1230498463741313e-05,
      "loss": 0.0493,
      "step": 14700
    },
    {
      "epoch": 0.4399964203681055,
      "grad_norm": 0.4604787826538086,
      "learning_rate": 1.1200668197953643e-05,
      "loss": 0.0148,
      "step": 14750
    },
    {
      "epoch": 0.4414879336574889,
      "grad_norm": 0.017657168209552765,
      "learning_rate": 1.1170837932165977e-05,
      "loss": 0.0293,
      "step": 14800
    },
    {
      "epoch": 0.4429794469468723,
      "grad_norm": 0.001623664633370936,
      "learning_rate": 1.1141007666378307e-05,
      "loss": 0.0326,
      "step": 14850
    },
    {
      "epoch": 0.4444709602362557,
      "grad_norm": 17.051002502441406,
      "learning_rate": 1.1111177400590641e-05,
      "loss": 0.0425,
      "step": 14900
    },
    {
      "epoch": 0.4459624735256391,
      "grad_norm": 9.41836166381836,
      "learning_rate": 1.1081347134802971e-05,
      "loss": 0.0585,
      "step": 14950
    },
    {
      "epoch": 0.4474539868150225,
      "grad_norm": 0.014437073841691017,
      "learning_rate": 1.1051516869015303e-05,
      "loss": 0.0311,
      "step": 15000
    },
    {
      "epoch": 0.4489455001044059,
      "grad_norm": 24.911476135253906,
      "learning_rate": 1.1021686603227636e-05,
      "loss": 0.0564,
      "step": 15050
    },
    {
      "epoch": 0.45043701339378933,
      "grad_norm": 0.0021263188682496548,
      "learning_rate": 1.0991856337439968e-05,
      "loss": 0.0469,
      "step": 15100
    },
    {
      "epoch": 0.45192852668317274,
      "grad_norm": 0.04246028512716293,
      "learning_rate": 1.0962026071652298e-05,
      "loss": 0.061,
      "step": 15150
    },
    {
      "epoch": 0.45342003997255614,
      "grad_norm": 0.21275226771831512,
      "learning_rate": 1.0932195805864632e-05,
      "loss": 0.0675,
      "step": 15200
    },
    {
      "epoch": 0.45491155326193955,
      "grad_norm": 0.07782147079706192,
      "learning_rate": 1.0902365540076962e-05,
      "loss": 0.0465,
      "step": 15250
    },
    {
      "epoch": 0.45640306655132296,
      "grad_norm": 0.0013816854916512966,
      "learning_rate": 1.0872535274289296e-05,
      "loss": 0.0323,
      "step": 15300
    },
    {
      "epoch": 0.45789457984070636,
      "grad_norm": 55.18843460083008,
      "learning_rate": 1.0842705008501626e-05,
      "loss": 0.0643,
      "step": 15350
    },
    {
      "epoch": 0.45938609313008977,
      "grad_norm": 0.0046965451911091805,
      "learning_rate": 1.0812874742713958e-05,
      "loss": 0.0074,
      "step": 15400
    },
    {
      "epoch": 0.4608776064194732,
      "grad_norm": 12.5281400680542,
      "learning_rate": 1.078304447692629e-05,
      "loss": 0.0514,
      "step": 15450
    },
    {
      "epoch": 0.4623691197088566,
      "grad_norm": 0.11606614291667938,
      "learning_rate": 1.0753214211138623e-05,
      "loss": 0.026,
      "step": 15500
    },
    {
      "epoch": 0.46386063299824004,
      "grad_norm": 0.01499907299876213,
      "learning_rate": 1.0723383945350953e-05,
      "loss": 0.0207,
      "step": 15550
    },
    {
      "epoch": 0.46535214628762345,
      "grad_norm": 0.0337754487991333,
      "learning_rate": 1.0693553679563287e-05,
      "loss": 0.0614,
      "step": 15600
    },
    {
      "epoch": 0.46684365957700685,
      "grad_norm": 0.0184635017067194,
      "learning_rate": 1.0663723413775617e-05,
      "loss": 0.0537,
      "step": 15650
    },
    {
      "epoch": 0.46833517286639026,
      "grad_norm": 0.028287075459957123,
      "learning_rate": 1.0633893147987951e-05,
      "loss": 0.0255,
      "step": 15700
    },
    {
      "epoch": 0.46982668615577367,
      "grad_norm": 0.017143458127975464,
      "learning_rate": 1.0604062882200281e-05,
      "loss": 0.0411,
      "step": 15750
    },
    {
      "epoch": 0.47131819944515707,
      "grad_norm": 0.10017768293619156,
      "learning_rate": 1.0574232616412614e-05,
      "loss": 0.0633,
      "step": 15800
    },
    {
      "epoch": 0.4728097127345405,
      "grad_norm": 0.00269333622418344,
      "learning_rate": 1.0544402350624946e-05,
      "loss": 0.0186,
      "step": 15850
    },
    {
      "epoch": 0.4743012260239239,
      "grad_norm": 0.03185546025633812,
      "learning_rate": 1.0514572084837276e-05,
      "loss": 0.0559,
      "step": 15900
    },
    {
      "epoch": 0.4757927393133073,
      "grad_norm": 0.008703003637492657,
      "learning_rate": 1.0484741819049608e-05,
      "loss": 0.0412,
      "step": 15950
    },
    {
      "epoch": 0.4772842526026907,
      "grad_norm": 0.07146584242582321,
      "learning_rate": 1.045491155326194e-05,
      "loss": 0.0458,
      "step": 16000
    },
    {
      "epoch": 0.4787757658920741,
      "grad_norm": 0.003886523423716426,
      "learning_rate": 1.0425081287474272e-05,
      "loss": 0.0501,
      "step": 16050
    },
    {
      "epoch": 0.4802672791814575,
      "grad_norm": 29.983808517456055,
      "learning_rate": 1.0395251021686603e-05,
      "loss": 0.0717,
      "step": 16100
    },
    {
      "epoch": 0.4817587924708409,
      "grad_norm": 7.283669471740723,
      "learning_rate": 1.0365420755898936e-05,
      "loss": 0.0811,
      "step": 16150
    },
    {
      "epoch": 0.4832503057602243,
      "grad_norm": 9.261153221130371,
      "learning_rate": 1.0335590490111267e-05,
      "loss": 0.0356,
      "step": 16200
    },
    {
      "epoch": 0.4847418190496077,
      "grad_norm": 0.37496694922447205,
      "learning_rate": 1.03057602243236e-05,
      "loss": 0.0363,
      "step": 16250
    },
    {
      "epoch": 0.48623333233899113,
      "grad_norm": 0.015642639249563217,
      "learning_rate": 1.0275929958535931e-05,
      "loss": 0.0119,
      "step": 16300
    },
    {
      "epoch": 0.48772484562837454,
      "grad_norm": 0.03442426770925522,
      "learning_rate": 1.0246099692748263e-05,
      "loss": 0.0427,
      "step": 16350
    },
    {
      "epoch": 0.48921635891775794,
      "grad_norm": 9.356895446777344,
      "learning_rate": 1.0216269426960595e-05,
      "loss": 0.0492,
      "step": 16400
    },
    {
      "epoch": 0.49070787220714135,
      "grad_norm": 6.190162658691406,
      "learning_rate": 1.0186439161172927e-05,
      "loss": 0.0913,
      "step": 16450
    },
    {
      "epoch": 0.49219938549652476,
      "grad_norm": 0.21635133028030396,
      "learning_rate": 1.0156608895385258e-05,
      "loss": 0.0232,
      "step": 16500
    },
    {
      "epoch": 0.49369089878590816,
      "grad_norm": 0.04351262003183365,
      "learning_rate": 1.0126778629597592e-05,
      "loss": 0.0574,
      "step": 16550
    },
    {
      "epoch": 0.49518241207529157,
      "grad_norm": 0.1962464302778244,
      "learning_rate": 1.0096948363809922e-05,
      "loss": 0.0235,
      "step": 16600
    },
    {
      "epoch": 0.496673925364675,
      "grad_norm": 22.074365615844727,
      "learning_rate": 1.0067118098022256e-05,
      "loss": 0.0787,
      "step": 16650
    },
    {
      "epoch": 0.49816543865405843,
      "grad_norm": 0.017477793619036674,
      "learning_rate": 1.0037287832234586e-05,
      "loss": 0.0352,
      "step": 16700
    },
    {
      "epoch": 0.49965695194344184,
      "grad_norm": 0.020633399486541748,
      "learning_rate": 1.0007457566446918e-05,
      "loss": 0.0098,
      "step": 16750
    },
    {
      "epoch": 0.5011484652328252,
      "grad_norm": 0.29578495025634766,
      "learning_rate": 9.977627300659249e-06,
      "loss": 0.0063,
      "step": 16800
    },
    {
      "epoch": 0.5026399785222087,
      "grad_norm": 0.014743633568286896,
      "learning_rate": 9.94779703487158e-06,
      "loss": 0.0857,
      "step": 16850
    },
    {
      "epoch": 0.504131491811592,
      "grad_norm": 0.09385619312524796,
      "learning_rate": 9.917966769083913e-06,
      "loss": 0.0355,
      "step": 16900
    },
    {
      "epoch": 0.5056230051009755,
      "grad_norm": 0.06431781500577927,
      "learning_rate": 9.888136503296245e-06,
      "loss": 0.0582,
      "step": 16950
    },
    {
      "epoch": 0.5071145183903588,
      "grad_norm": 0.18238824605941772,
      "learning_rate": 9.858306237508577e-06,
      "loss": 0.0636,
      "step": 17000
    },
    {
      "epoch": 0.5086060316797423,
      "grad_norm": 0.231343075633049,
      "learning_rate": 9.828475971720909e-06,
      "loss": 0.0448,
      "step": 17050
    },
    {
      "epoch": 0.5100975449691256,
      "grad_norm": 0.013732803985476494,
      "learning_rate": 9.798645705933241e-06,
      "loss": 0.0454,
      "step": 17100
    },
    {
      "epoch": 0.5115890582585091,
      "grad_norm": 0.0036387029103934765,
      "learning_rate": 9.768815440145573e-06,
      "loss": 0.0288,
      "step": 17150
    },
    {
      "epoch": 0.5130805715478924,
      "grad_norm": 0.003312651999294758,
      "learning_rate": 9.738985174357904e-06,
      "loss": 0.0473,
      "step": 17200
    },
    {
      "epoch": 0.5145720848372759,
      "grad_norm": 0.04443447291851044,
      "learning_rate": 9.709154908570236e-06,
      "loss": 0.0607,
      "step": 17250
    },
    {
      "epoch": 0.5160635981266594,
      "grad_norm": 0.009701513685286045,
      "learning_rate": 9.679324642782568e-06,
      "loss": 0.0369,
      "step": 17300
    },
    {
      "epoch": 0.5175551114160427,
      "grad_norm": 0.008530203253030777,
      "learning_rate": 9.6494943769949e-06,
      "loss": 0.0376,
      "step": 17350
    },
    {
      "epoch": 0.5190466247054262,
      "grad_norm": 0.006315720733255148,
      "learning_rate": 9.619664111207232e-06,
      "loss": 0.0147,
      "step": 17400
    },
    {
      "epoch": 0.5205381379948095,
      "grad_norm": 0.042593155056238174,
      "learning_rate": 9.589833845419564e-06,
      "loss": 0.0515,
      "step": 17450
    },
    {
      "epoch": 0.522029651284193,
      "grad_norm": 0.009363409131765366,
      "learning_rate": 9.560003579631896e-06,
      "loss": 0.048,
      "step": 17500
    },
    {
      "epoch": 0.5235211645735763,
      "grad_norm": 0.061092980206012726,
      "learning_rate": 9.530173313844228e-06,
      "loss": 0.0288,
      "step": 17550
    },
    {
      "epoch": 0.5250126778629598,
      "grad_norm": 0.26427480578422546,
      "learning_rate": 9.500343048056559e-06,
      "loss": 0.0653,
      "step": 17600
    },
    {
      "epoch": 0.5265041911523431,
      "grad_norm": 0.2719956934452057,
      "learning_rate": 9.47051278226889e-06,
      "loss": 0.0492,
      "step": 17650
    },
    {
      "epoch": 0.5279957044417266,
      "grad_norm": 0.01826217584311962,
      "learning_rate": 9.440682516481223e-06,
      "loss": 0.0664,
      "step": 17700
    },
    {
      "epoch": 0.52948721773111,
      "grad_norm": 0.006820198148488998,
      "learning_rate": 9.410852250693553e-06,
      "loss": 0.0362,
      "step": 17750
    },
    {
      "epoch": 0.5309787310204934,
      "grad_norm": 0.010864801704883575,
      "learning_rate": 9.381021984905885e-06,
      "loss": 0.034,
      "step": 17800
    },
    {
      "epoch": 0.5324702443098768,
      "grad_norm": 0.01922912336885929,
      "learning_rate": 9.351191719118217e-06,
      "loss": 0.0794,
      "step": 17850
    },
    {
      "epoch": 0.5339617575992602,
      "grad_norm": 0.00954693928360939,
      "learning_rate": 9.32136145333055e-06,
      "loss": 0.0442,
      "step": 17900
    },
    {
      "epoch": 0.5354532708886436,
      "grad_norm": 0.010151144117116928,
      "learning_rate": 9.291531187542882e-06,
      "loss": 0.0333,
      "step": 17950
    },
    {
      "epoch": 0.536944784178027,
      "grad_norm": 0.0025486096274107695,
      "learning_rate": 9.261700921755214e-06,
      "loss": 0.0244,
      "step": 18000
    },
    {
      "epoch": 0.5384362974674104,
      "grad_norm": 0.022473080083727837,
      "learning_rate": 9.231870655967546e-06,
      "loss": 0.0565,
      "step": 18050
    },
    {
      "epoch": 0.5399278107567939,
      "grad_norm": 0.0538884736597538,
      "learning_rate": 9.202040390179878e-06,
      "loss": 0.0445,
      "step": 18100
    },
    {
      "epoch": 0.5414193240461772,
      "grad_norm": 0.07194648683071136,
      "learning_rate": 9.172210124392208e-06,
      "loss": 0.0258,
      "step": 18150
    },
    {
      "epoch": 0.5429108373355607,
      "grad_norm": 0.5578157305717468,
      "learning_rate": 9.14237985860454e-06,
      "loss": 0.0764,
      "step": 18200
    },
    {
      "epoch": 0.544402350624944,
      "grad_norm": 0.0022908635437488556,
      "learning_rate": 9.112549592816873e-06,
      "loss": 0.0331,
      "step": 18250
    },
    {
      "epoch": 0.5458938639143275,
      "grad_norm": 0.3156689405441284,
      "learning_rate": 9.082719327029205e-06,
      "loss": 0.0435,
      "step": 18300
    },
    {
      "epoch": 0.5473853772037108,
      "grad_norm": 0.10491690039634705,
      "learning_rate": 9.052889061241537e-06,
      "loss": 0.0524,
      "step": 18350
    },
    {
      "epoch": 0.5488768904930943,
      "grad_norm": 0.36185595393180847,
      "learning_rate": 9.023058795453869e-06,
      "loss": 0.0474,
      "step": 18400
    },
    {
      "epoch": 0.5503684037824778,
      "grad_norm": 0.046782322227954865,
      "learning_rate": 8.993228529666201e-06,
      "loss": 0.0394,
      "step": 18450
    },
    {
      "epoch": 0.5518599170718611,
      "grad_norm": 0.28724634647369385,
      "learning_rate": 8.963398263878533e-06,
      "loss": 0.0782,
      "step": 18500
    },
    {
      "epoch": 0.5533514303612446,
      "grad_norm": 0.06972429156303406,
      "learning_rate": 8.933567998090863e-06,
      "loss": 0.0612,
      "step": 18550
    },
    {
      "epoch": 0.5548429436506279,
      "grad_norm": 7.90209436416626,
      "learning_rate": 8.903737732303196e-06,
      "loss": 0.047,
      "step": 18600
    },
    {
      "epoch": 0.5563344569400114,
      "grad_norm": 0.015431990846991539,
      "learning_rate": 8.873907466515528e-06,
      "loss": 0.0675,
      "step": 18650
    },
    {
      "epoch": 0.5578259702293947,
      "grad_norm": 0.0033829882740974426,
      "learning_rate": 8.84407720072786e-06,
      "loss": 0.0432,
      "step": 18700
    },
    {
      "epoch": 0.5593174835187782,
      "grad_norm": 0.6832978129386902,
      "learning_rate": 8.814246934940192e-06,
      "loss": 0.0645,
      "step": 18750
    },
    {
      "epoch": 0.5608089968081615,
      "grad_norm": 0.1385907679796219,
      "learning_rate": 8.784416669152522e-06,
      "loss": 0.02,
      "step": 18800
    },
    {
      "epoch": 0.562300510097545,
      "grad_norm": 11.238883018493652,
      "learning_rate": 8.754586403364854e-06,
      "loss": 0.0866,
      "step": 18850
    },
    {
      "epoch": 0.5637920233869284,
      "grad_norm": 0.006413851864635944,
      "learning_rate": 8.724756137577186e-06,
      "loss": 0.0371,
      "step": 18900
    },
    {
      "epoch": 0.5652835366763118,
      "grad_norm": 0.0042884997092187405,
      "learning_rate": 8.694925871789518e-06,
      "loss": 0.0186,
      "step": 18950
    },
    {
      "epoch": 0.5667750499656952,
      "grad_norm": 0.0022587247658520937,
      "learning_rate": 8.66509560600185e-06,
      "loss": 0.0047,
      "step": 19000
    },
    {
      "epoch": 0.5682665632550786,
      "grad_norm": 0.002817890141159296,
      "learning_rate": 8.635265340214181e-06,
      "loss": 0.0414,
      "step": 19050
    },
    {
      "epoch": 0.569758076544462,
      "grad_norm": 0.01435085292905569,
      "learning_rate": 8.605435074426513e-06,
      "loss": 0.0259,
      "step": 19100
    },
    {
      "epoch": 0.5712495898338454,
      "grad_norm": 22.20964813232422,
      "learning_rate": 8.575604808638845e-06,
      "loss": 0.017,
      "step": 19150
    },
    {
      "epoch": 0.5727411031232288,
      "grad_norm": 0.4318196177482605,
      "learning_rate": 8.545774542851177e-06,
      "loss": 0.047,
      "step": 19200
    },
    {
      "epoch": 0.5742326164126123,
      "grad_norm": 0.006148000247776508,
      "learning_rate": 8.51594427706351e-06,
      "loss": 0.0406,
      "step": 19250
    },
    {
      "epoch": 0.5757241297019956,
      "grad_norm": 0.0033488988410681486,
      "learning_rate": 8.486114011275841e-06,
      "loss": 0.0476,
      "step": 19300
    },
    {
      "epoch": 0.5772156429913791,
      "grad_norm": 0.0027804947458207607,
      "learning_rate": 8.456283745488174e-06,
      "loss": 0.0583,
      "step": 19350
    },
    {
      "epoch": 0.5787071562807624,
      "grad_norm": 0.002718308474868536,
      "learning_rate": 8.426453479700506e-06,
      "loss": 0.0237,
      "step": 19400
    },
    {
      "epoch": 0.5801986695701459,
      "grad_norm": 0.0009633753215894103,
      "learning_rate": 8.396623213912836e-06,
      "loss": 0.0171,
      "step": 19450
    },
    {
      "epoch": 0.5816901828595292,
      "grad_norm": 0.0027259199414402246,
      "learning_rate": 8.366792948125168e-06,
      "loss": 0.0336,
      "step": 19500
    },
    {
      "epoch": 0.5831816961489127,
      "grad_norm": 0.015181059017777443,
      "learning_rate": 8.3369626823375e-06,
      "loss": 0.0274,
      "step": 19550
    },
    {
      "epoch": 0.5846732094382961,
      "grad_norm": 0.004845039453357458,
      "learning_rate": 8.307132416549832e-06,
      "loss": 0.0252,
      "step": 19600
    },
    {
      "epoch": 0.5861647227276795,
      "grad_norm": 7.033831596374512,
      "learning_rate": 8.277302150762164e-06,
      "loss": 0.0641,
      "step": 19650
    },
    {
      "epoch": 0.587656236017063,
      "grad_norm": 0.004486124962568283,
      "learning_rate": 8.247471884974496e-06,
      "loss": 0.0677,
      "step": 19700
    },
    {
      "epoch": 0.5891477493064463,
      "grad_norm": 12.16321849822998,
      "learning_rate": 8.217641619186829e-06,
      "loss": 0.0222,
      "step": 19750
    },
    {
      "epoch": 0.5906392625958298,
      "grad_norm": 0.002268758835271001,
      "learning_rate": 8.18781135339916e-06,
      "loss": 0.0472,
      "step": 19800
    },
    {
      "epoch": 0.5921307758852131,
      "grad_norm": 1.1363283395767212,
      "learning_rate": 8.157981087611491e-06,
      "loss": 0.0375,
      "step": 19850
    },
    {
      "epoch": 0.5936222891745966,
      "grad_norm": 0.007804966997355223,
      "learning_rate": 8.128150821823823e-06,
      "loss": 0.0376,
      "step": 19900
    },
    {
      "epoch": 0.5951138024639799,
      "grad_norm": 0.0016863241326063871,
      "learning_rate": 8.098320556036155e-06,
      "loss": 0.0106,
      "step": 19950
    },
    {
      "epoch": 0.5966053157533634,
      "grad_norm": 0.0016333494568243623,
      "learning_rate": 8.068490290248486e-06,
      "loss": 0.0309,
      "step": 20000
    },
    {
      "epoch": 0.5980968290427467,
      "grad_norm": 0.17370650172233582,
      "learning_rate": 8.038660024460818e-06,
      "loss": 0.0497,
      "step": 20050
    },
    {
      "epoch": 0.5995883423321302,
      "grad_norm": 0.2558578550815582,
      "learning_rate": 8.00882975867315e-06,
      "loss": 0.057,
      "step": 20100
    },
    {
      "epoch": 0.6010798556215136,
      "grad_norm": 0.0025751234497874975,
      "learning_rate": 7.978999492885482e-06,
      "loss": 0.0256,
      "step": 20150
    },
    {
      "epoch": 0.602571368910897,
      "grad_norm": 0.642256498336792,
      "learning_rate": 7.949169227097814e-06,
      "loss": 0.0161,
      "step": 20200
    },
    {
      "epoch": 0.6040628822002804,
      "grad_norm": 0.12814535200595856,
      "learning_rate": 7.919338961310146e-06,
      "loss": 0.0537,
      "step": 20250
    },
    {
      "epoch": 0.6055543954896638,
      "grad_norm": 0.013586286455392838,
      "learning_rate": 7.889508695522478e-06,
      "loss": 0.0226,
      "step": 20300
    },
    {
      "epoch": 0.6070459087790472,
      "grad_norm": 0.004685025196522474,
      "learning_rate": 7.859678429734809e-06,
      "loss": 0.0682,
      "step": 20350
    },
    {
      "epoch": 0.6085374220684306,
      "grad_norm": 0.13241226971149445,
      "learning_rate": 7.82984816394714e-06,
      "loss": 0.0377,
      "step": 20400
    },
    {
      "epoch": 0.610028935357814,
      "grad_norm": 0.09175823628902435,
      "learning_rate": 7.800017898159473e-06,
      "loss": 0.0295,
      "step": 20450
    },
    {
      "epoch": 0.6115204486471975,
      "grad_norm": 0.030018268153071404,
      "learning_rate": 7.770187632371805e-06,
      "loss": 0.0421,
      "step": 20500
    },
    {
      "epoch": 0.6130119619365808,
      "grad_norm": 0.34595561027526855,
      "learning_rate": 7.740357366584137e-06,
      "loss": 0.0573,
      "step": 20550
    },
    {
      "epoch": 0.6145034752259643,
      "grad_norm": 0.0019390396773815155,
      "learning_rate": 7.710527100796469e-06,
      "loss": 0.0368,
      "step": 20600
    },
    {
      "epoch": 0.6159949885153476,
      "grad_norm": 0.014550309628248215,
      "learning_rate": 7.680696835008801e-06,
      "loss": 0.0381,
      "step": 20650
    },
    {
      "epoch": 0.6174865018047311,
      "grad_norm": 0.10090598464012146,
      "learning_rate": 7.650866569221133e-06,
      "loss": 0.0348,
      "step": 20700
    },
    {
      "epoch": 0.6189780150941145,
      "grad_norm": 7.730736255645752,
      "learning_rate": 7.6210363034334645e-06,
      "loss": 0.0539,
      "step": 20750
    },
    {
      "epoch": 0.6204695283834979,
      "grad_norm": 0.022935817018151283,
      "learning_rate": 7.591206037645797e-06,
      "loss": 0.0567,
      "step": 20800
    },
    {
      "epoch": 0.6219610416728814,
      "grad_norm": 0.8249260783195496,
      "learning_rate": 7.561375771858128e-06,
      "loss": 0.048,
      "step": 20850
    },
    {
      "epoch": 0.6234525549622647,
      "grad_norm": 0.001900224480777979,
      "learning_rate": 7.53154550607046e-06,
      "loss": 0.0343,
      "step": 20900
    },
    {
      "epoch": 0.6249440682516482,
      "grad_norm": 0.10716727375984192,
      "learning_rate": 7.501715240282792e-06,
      "loss": 0.0692,
      "step": 20950
    },
    {
      "epoch": 0.6264355815410315,
      "grad_norm": 1.765708327293396,
      "learning_rate": 7.471884974495124e-06,
      "loss": 0.0245,
      "step": 21000
    },
    {
      "epoch": 0.627927094830415,
      "grad_norm": 0.003638859838247299,
      "learning_rate": 7.442054708707455e-06,
      "loss": 0.0167,
      "step": 21050
    },
    {
      "epoch": 0.6294186081197983,
      "grad_norm": 0.0010350527008995414,
      "learning_rate": 7.412224442919787e-06,
      "loss": 0.0493,
      "step": 21100
    },
    {
      "epoch": 0.6309101214091818,
      "grad_norm": 7.140310287475586,
      "learning_rate": 7.382394177132119e-06,
      "loss": 0.0432,
      "step": 21150
    },
    {
      "epoch": 0.6324016346985651,
      "grad_norm": 0.018994266167283058,
      "learning_rate": 7.35256391134445e-06,
      "loss": 0.0512,
      "step": 21200
    },
    {
      "epoch": 0.6338931479879486,
      "grad_norm": 0.0020843534730374813,
      "learning_rate": 7.322733645556782e-06,
      "loss": 0.0296,
      "step": 21250
    },
    {
      "epoch": 0.635384661277332,
      "grad_norm": 0.9971545934677124,
      "learning_rate": 7.292903379769114e-06,
      "loss": 0.0716,
      "step": 21300
    },
    {
      "epoch": 0.6368761745667154,
      "grad_norm": 0.04678632318973541,
      "learning_rate": 7.263073113981446e-06,
      "loss": 0.0394,
      "step": 21350
    },
    {
      "epoch": 0.6383676878560988,
      "grad_norm": 0.01018223911523819,
      "learning_rate": 7.2332428481937775e-06,
      "loss": 0.0044,
      "step": 21400
    },
    {
      "epoch": 0.6398592011454822,
      "grad_norm": 9.011585235595703,
      "learning_rate": 7.2034125824061096e-06,
      "loss": 0.0414,
      "step": 21450
    },
    {
      "epoch": 0.6413507144348656,
      "grad_norm": 0.008519061841070652,
      "learning_rate": 7.173582316618442e-06,
      "loss": 0.0722,
      "step": 21500
    },
    {
      "epoch": 0.642842227724249,
      "grad_norm": 0.06066083163022995,
      "learning_rate": 7.143752050830774e-06,
      "loss": 0.0227,
      "step": 21550
    },
    {
      "epoch": 0.6443337410136324,
      "grad_norm": 0.018548227846622467,
      "learning_rate": 7.113921785043105e-06,
      "loss": 0.0382,
      "step": 21600
    },
    {
      "epoch": 0.6458252543030158,
      "grad_norm": 0.05855170264840126,
      "learning_rate": 7.084091519255437e-06,
      "loss": 0.0386,
      "step": 21650
    },
    {
      "epoch": 0.6473167675923992,
      "grad_norm": 0.03707857429981232,
      "learning_rate": 7.054261253467769e-06,
      "loss": 0.0404,
      "step": 21700
    },
    {
      "epoch": 0.6488082808817827,
      "grad_norm": 0.13392099738121033,
      "learning_rate": 7.024430987680101e-06,
      "loss": 0.0643,
      "step": 21750
    },
    {
      "epoch": 0.650299794171166,
      "grad_norm": 0.05232008174061775,
      "learning_rate": 6.9946007218924325e-06,
      "loss": 0.0567,
      "step": 21800
    },
    {
      "epoch": 0.6517913074605495,
      "grad_norm": 0.057411134243011475,
      "learning_rate": 6.964770456104765e-06,
      "loss": 0.0516,
      "step": 21850
    },
    {
      "epoch": 0.6532828207499329,
      "grad_norm": 0.07444540411233902,
      "learning_rate": 6.934940190317097e-06,
      "loss": 0.0543,
      "step": 21900
    },
    {
      "epoch": 0.6547743340393163,
      "grad_norm": 0.07422727346420288,
      "learning_rate": 6.905109924529429e-06,
      "loss": 0.0378,
      "step": 21950
    },
    {
      "epoch": 0.6562658473286997,
      "grad_norm": 0.6030718684196472,
      "learning_rate": 6.87527965874176e-06,
      "loss": 0.0447,
      "step": 22000
    },
    {
      "epoch": 0.6577573606180831,
      "grad_norm": 0.024980690330266953,
      "learning_rate": 6.845449392954092e-06,
      "loss": 0.0318,
      "step": 22050
    },
    {
      "epoch": 0.6592488739074666,
      "grad_norm": 0.01779893785715103,
      "learning_rate": 6.815619127166424e-06,
      "loss": 0.0565,
      "step": 22100
    },
    {
      "epoch": 0.6607403871968499,
      "grad_norm": 0.1140696257352829,
      "learning_rate": 6.785788861378756e-06,
      "loss": 0.0506,
      "step": 22150
    },
    {
      "epoch": 0.6622319004862334,
      "grad_norm": 0.005714329890906811,
      "learning_rate": 6.7559585955910876e-06,
      "loss": 0.0572,
      "step": 22200
    },
    {
      "epoch": 0.6637234137756167,
      "grad_norm": 0.009530982933938503,
      "learning_rate": 6.726128329803419e-06,
      "loss": 0.0524,
      "step": 22250
    },
    {
      "epoch": 0.6652149270650002,
      "grad_norm": 0.0400814488530159,
      "learning_rate": 6.69629806401575e-06,
      "loss": 0.0451,
      "step": 22300
    },
    {
      "epoch": 0.6667064403543835,
      "grad_norm": 0.06835300475358963,
      "learning_rate": 6.666467798228082e-06,
      "loss": 0.0438,
      "step": 22350
    },
    {
      "epoch": 0.668197953643767,
      "grad_norm": 28.36301040649414,
      "learning_rate": 6.636637532440414e-06,
      "loss": 0.0509,
      "step": 22400
    },
    {
      "epoch": 0.6696894669331503,
      "grad_norm": 0.10868513584136963,
      "learning_rate": 6.606807266652746e-06,
      "loss": 0.0247,
      "step": 22450
    },
    {
      "epoch": 0.6711809802225338,
      "grad_norm": 0.14566218852996826,
      "learning_rate": 6.576977000865078e-06,
      "loss": 0.0468,
      "step": 22500
    },
    {
      "epoch": 0.6726724935119172,
      "grad_norm": 0.01032822672277689,
      "learning_rate": 6.54714673507741e-06,
      "loss": 0.0569,
      "step": 22550
    },
    {
      "epoch": 0.6741640068013006,
      "grad_norm": 0.11411381512880325,
      "learning_rate": 6.517316469289742e-06,
      "loss": 0.048,
      "step": 22600
    },
    {
      "epoch": 0.675655520090684,
      "grad_norm": 18.08333969116211,
      "learning_rate": 6.487486203502074e-06,
      "loss": 0.0362,
      "step": 22650
    },
    {
      "epoch": 0.6771470333800674,
      "grad_norm": 0.5255624055862427,
      "learning_rate": 6.457655937714405e-06,
      "loss": 0.0489,
      "step": 22700
    },
    {
      "epoch": 0.6786385466694508,
      "grad_norm": 0.6056563258171082,
      "learning_rate": 6.427825671926737e-06,
      "loss": 0.0694,
      "step": 22750
    },
    {
      "epoch": 0.6801300599588342,
      "grad_norm": 0.0026527242735028267,
      "learning_rate": 6.397995406139069e-06,
      "loss": 0.0184,
      "step": 22800
    },
    {
      "epoch": 0.6816215732482176,
      "grad_norm": 0.004430024418979883,
      "learning_rate": 6.368165140351401e-06,
      "loss": 0.0602,
      "step": 22850
    },
    {
      "epoch": 0.683113086537601,
      "grad_norm": 0.47573843598365784,
      "learning_rate": 6.338334874563733e-06,
      "loss": 0.0365,
      "step": 22900
    },
    {
      "epoch": 0.6846045998269844,
      "grad_norm": 0.014049284160137177,
      "learning_rate": 6.308504608776065e-06,
      "loss": 0.0284,
      "step": 22950
    },
    {
      "epoch": 0.6860961131163679,
      "grad_norm": 0.0009249826543964446,
      "learning_rate": 6.278674342988397e-06,
      "loss": 0.026,
      "step": 23000
    },
    {
      "epoch": 0.6875876264057513,
      "grad_norm": 22.68345069885254,
      "learning_rate": 6.248844077200729e-06,
      "loss": 0.0452,
      "step": 23050
    },
    {
      "epoch": 0.6890791396951347,
      "grad_norm": 0.0014991738134995103,
      "learning_rate": 6.21901381141306e-06,
      "loss": 0.0377,
      "step": 23100
    },
    {
      "epoch": 0.6905706529845181,
      "grad_norm": 0.00946060661226511,
      "learning_rate": 6.189183545625392e-06,
      "loss": 0.043,
      "step": 23150
    },
    {
      "epoch": 0.6920621662739015,
      "grad_norm": 0.01304231584072113,
      "learning_rate": 6.159353279837724e-06,
      "loss": 0.0273,
      "step": 23200
    },
    {
      "epoch": 0.693553679563285,
      "grad_norm": 0.05754712596535683,
      "learning_rate": 6.1295230140500564e-06,
      "loss": 0.035,
      "step": 23250
    },
    {
      "epoch": 0.6950451928526683,
      "grad_norm": 0.028736252337694168,
      "learning_rate": 6.099692748262388e-06,
      "loss": 0.0661,
      "step": 23300
    },
    {
      "epoch": 0.6965367061420518,
      "grad_norm": 0.015137947164475918,
      "learning_rate": 6.06986248247472e-06,
      "loss": 0.0097,
      "step": 23350
    },
    {
      "epoch": 0.6980282194314351,
      "grad_norm": 0.003801093203946948,
      "learning_rate": 6.040032216687051e-06,
      "loss": 0.02,
      "step": 23400
    },
    {
      "epoch": 0.6995197327208186,
      "grad_norm": 0.004813299980014563,
      "learning_rate": 6.010201950899382e-06,
      "loss": 0.0592,
      "step": 23450
    },
    {
      "epoch": 0.7010112460102019,
      "grad_norm": 0.002703301142901182,
      "learning_rate": 5.980371685111714e-06,
      "loss": 0.0504,
      "step": 23500
    },
    {
      "epoch": 0.7025027592995854,
      "grad_norm": 0.002589964307844639,
      "learning_rate": 5.9505414193240465e-06,
      "loss": 0.0277,
      "step": 23550
    },
    {
      "epoch": 0.7039942725889687,
      "grad_norm": 0.02705412730574608,
      "learning_rate": 5.9207111535363786e-06,
      "loss": 0.0191,
      "step": 23600
    },
    {
      "epoch": 0.7054857858783522,
      "grad_norm": 0.11844178289175034,
      "learning_rate": 5.89088088774871e-06,
      "loss": 0.0109,
      "step": 23650
    },
    {
      "epoch": 0.7069772991677356,
      "grad_norm": 0.22795090079307556,
      "learning_rate": 5.861050621961042e-06,
      "loss": 0.03,
      "step": 23700
    },
    {
      "epoch": 0.708468812457119,
      "grad_norm": 0.008720834739506245,
      "learning_rate": 5.831220356173374e-06,
      "loss": 0.0062,
      "step": 23750
    },
    {
      "epoch": 0.7099603257465024,
      "grad_norm": 74.72564697265625,
      "learning_rate": 5.801390090385706e-06,
      "loss": 0.0546,
      "step": 23800
    },
    {
      "epoch": 0.7114518390358858,
      "grad_norm": 0.05239160731434822,
      "learning_rate": 5.771559824598037e-06,
      "loss": 0.0402,
      "step": 23850
    },
    {
      "epoch": 0.7129433523252692,
      "grad_norm": 0.004324144683778286,
      "learning_rate": 5.7417295588103694e-06,
      "loss": 0.0195,
      "step": 23900
    },
    {
      "epoch": 0.7144348656146526,
      "grad_norm": 0.07152524590492249,
      "learning_rate": 5.7118992930227015e-06,
      "loss": 0.036,
      "step": 23950
    },
    {
      "epoch": 0.715926378904036,
      "grad_norm": 9.990283966064453,
      "learning_rate": 5.682069027235033e-06,
      "loss": 0.0145,
      "step": 24000
    },
    {
      "epoch": 0.7174178921934194,
      "grad_norm": 0.07206312566995621,
      "learning_rate": 5.652238761447365e-06,
      "loss": 0.0561,
      "step": 24050
    },
    {
      "epoch": 0.7189094054828028,
      "grad_norm": 0.0053629823960363865,
      "learning_rate": 5.622408495659697e-06,
      "loss": 0.0179,
      "step": 24100
    },
    {
      "epoch": 0.7204009187721863,
      "grad_norm": 28.579572677612305,
      "learning_rate": 5.592578229872029e-06,
      "loss": 0.034,
      "step": 24150
    },
    {
      "epoch": 0.7218924320615697,
      "grad_norm": 0.021565720438957214,
      "learning_rate": 5.56274796408436e-06,
      "loss": 0.0466,
      "step": 24200
    },
    {
      "epoch": 0.7233839453509531,
      "grad_norm": 0.0019835345447063446,
      "learning_rate": 5.532917698296692e-06,
      "loss": 0.0383,
      "step": 24250
    },
    {
      "epoch": 0.7248754586403365,
      "grad_norm": 0.007809460628777742,
      "learning_rate": 5.5030874325090245e-06,
      "loss": 0.0398,
      "step": 24300
    },
    {
      "epoch": 0.7263669719297199,
      "grad_norm": 9.891064643859863,
      "learning_rate": 5.4732571667213566e-06,
      "loss": 0.0572,
      "step": 24350
    },
    {
      "epoch": 0.7278584852191033,
      "grad_norm": 0.2297782152891159,
      "learning_rate": 5.443426900933688e-06,
      "loss": 0.0502,
      "step": 24400
    },
    {
      "epoch": 0.7293499985084867,
      "grad_norm": 0.1539933979511261,
      "learning_rate": 5.41359663514602e-06,
      "loss": 0.0406,
      "step": 24450
    },
    {
      "epoch": 0.7308415117978702,
      "grad_norm": 0.1510235071182251,
      "learning_rate": 5.383766369358352e-06,
      "loss": 0.0289,
      "step": 24500
    },
    {
      "epoch": 0.7323330250872535,
      "grad_norm": 0.0018683832604438066,
      "learning_rate": 5.353936103570682e-06,
      "loss": 0.0261,
      "step": 24550
    },
    {
      "epoch": 0.733824538376637,
      "grad_norm": 0.002414270769804716,
      "learning_rate": 5.3241058377830145e-06,
      "loss": 0.049,
      "step": 24600
    },
    {
      "epoch": 0.7353160516660203,
      "grad_norm": 10.179737091064453,
      "learning_rate": 5.294275571995347e-06,
      "loss": 0.0584,
      "step": 24650
    },
    {
      "epoch": 0.7368075649554038,
      "grad_norm": 0.05612920597195625,
      "learning_rate": 5.264445306207679e-06,
      "loss": 0.0296,
      "step": 24700
    },
    {
      "epoch": 0.7382990782447871,
      "grad_norm": 0.0016777587588876486,
      "learning_rate": 5.23461504042001e-06,
      "loss": 0.0204,
      "step": 24750
    },
    {
      "epoch": 0.7397905915341706,
      "grad_norm": 0.0011513924691826105,
      "learning_rate": 5.204784774632342e-06,
      "loss": 0.0467,
      "step": 24800
    },
    {
      "epoch": 0.741282104823554,
      "grad_norm": 0.013361089862883091,
      "learning_rate": 5.174954508844674e-06,
      "loss": 0.0393,
      "step": 24850
    },
    {
      "epoch": 0.7427736181129374,
      "grad_norm": 0.14004230499267578,
      "learning_rate": 5.145124243057006e-06,
      "loss": 0.027,
      "step": 24900
    },
    {
      "epoch": 0.7442651314023208,
      "grad_norm": 0.0657629668712616,
      "learning_rate": 5.1152939772693375e-06,
      "loss": 0.0469,
      "step": 24950
    },
    {
      "epoch": 0.7457566446917042,
      "grad_norm": 0.0014565507881343365,
      "learning_rate": 5.0854637114816695e-06,
      "loss": 0.0503,
      "step": 25000
    },
    {
      "epoch": 0.7472481579810876,
      "grad_norm": 0.0011315640294924378,
      "learning_rate": 5.055633445694002e-06,
      "loss": 0.0368,
      "step": 25050
    },
    {
      "epoch": 0.748739671270471,
      "grad_norm": 0.14537160098552704,
      "learning_rate": 5.025803179906334e-06,
      "loss": 0.0217,
      "step": 25100
    },
    {
      "epoch": 0.7502311845598544,
      "grad_norm": 0.0009122187038883567,
      "learning_rate": 4.995972914118665e-06,
      "loss": 0.0485,
      "step": 25150
    },
    {
      "epoch": 0.7517226978492378,
      "grad_norm": 0.010677761398255825,
      "learning_rate": 4.966142648330997e-06,
      "loss": 0.0127,
      "step": 25200
    },
    {
      "epoch": 0.7532142111386212,
      "grad_norm": 0.00078270782250911,
      "learning_rate": 4.936312382543329e-06,
      "loss": 0.0131,
      "step": 25250
    },
    {
      "epoch": 0.7547057244280047,
      "grad_norm": 19.27581787109375,
      "learning_rate": 4.906482116755661e-06,
      "loss": 0.069,
      "step": 25300
    },
    {
      "epoch": 0.7561972377173881,
      "grad_norm": 0.1046837791800499,
      "learning_rate": 4.8766518509679925e-06,
      "loss": 0.0485,
      "step": 25350
    },
    {
      "epoch": 0.7576887510067715,
      "grad_norm": 6.492789268493652,
      "learning_rate": 4.846821585180324e-06,
      "loss": 0.0399,
      "step": 25400
    },
    {
      "epoch": 0.7591802642961549,
      "grad_norm": 0.17617638409137726,
      "learning_rate": 4.816991319392656e-06,
      "loss": 0.0444,
      "step": 25450
    },
    {
      "epoch": 0.7606717775855383,
      "grad_norm": 0.0019293964141979814,
      "learning_rate": 4.787161053604988e-06,
      "loss": 0.0084,
      "step": 25500
    },
    {
      "epoch": 0.7621632908749217,
      "grad_norm": 0.010709776543080807,
      "learning_rate": 4.75733078781732e-06,
      "loss": 0.029,
      "step": 25550
    },
    {
      "epoch": 0.7636548041643051,
      "grad_norm": 5.365211486816406,
      "learning_rate": 4.727500522029651e-06,
      "loss": 0.06,
      "step": 25600
    },
    {
      "epoch": 0.7651463174536886,
      "grad_norm": 0.050853002816438675,
      "learning_rate": 4.697670256241983e-06,
      "loss": 0.0272,
      "step": 25650
    },
    {
      "epoch": 0.7666378307430719,
      "grad_norm": 0.04386115074157715,
      "learning_rate": 4.6678399904543155e-06,
      "loss": 0.0654,
      "step": 25700
    },
    {
      "epoch": 0.7681293440324554,
      "grad_norm": 0.24742037057876587,
      "learning_rate": 4.6380097246666476e-06,
      "loss": 0.023,
      "step": 25750
    },
    {
      "epoch": 0.7696208573218387,
      "grad_norm": 0.05692672356963158,
      "learning_rate": 4.608179458878979e-06,
      "loss": 0.0155,
      "step": 25800
    },
    {
      "epoch": 0.7711123706112222,
      "grad_norm": 0.05256766080856323,
      "learning_rate": 4.578349193091311e-06,
      "loss": 0.0385,
      "step": 25850
    },
    {
      "epoch": 0.7726038839006055,
      "grad_norm": 0.004646707326173782,
      "learning_rate": 4.548518927303643e-06,
      "loss": 0.0309,
      "step": 25900
    },
    {
      "epoch": 0.774095397189989,
      "grad_norm": 0.002584274159744382,
      "learning_rate": 4.518688661515975e-06,
      "loss": 0.0198,
      "step": 25950
    },
    {
      "epoch": 0.7755869104793723,
      "grad_norm": 0.03960517793893814,
      "learning_rate": 4.488858395728306e-06,
      "loss": 0.0513,
      "step": 26000
    },
    {
      "epoch": 0.7770784237687558,
      "grad_norm": 0.009854882955551147,
      "learning_rate": 4.4590281299406376e-06,
      "loss": 0.0518,
      "step": 26050
    },
    {
      "epoch": 0.7785699370581391,
      "grad_norm": 13.553335189819336,
      "learning_rate": 4.42919786415297e-06,
      "loss": 0.0325,
      "step": 26100
    },
    {
      "epoch": 0.7800614503475226,
      "grad_norm": 10.476682662963867,
      "learning_rate": 4.399367598365302e-06,
      "loss": 0.0372,
      "step": 26150
    },
    {
      "epoch": 0.781552963636906,
      "grad_norm": 0.3481423556804657,
      "learning_rate": 4.369537332577634e-06,
      "loss": 0.0337,
      "step": 26200
    },
    {
      "epoch": 0.7830444769262894,
      "grad_norm": 0.0010696465615183115,
      "learning_rate": 4.339707066789965e-06,
      "loss": 0.0428,
      "step": 26250
    },
    {
      "epoch": 0.7845359902156728,
      "grad_norm": 0.0093498220667243,
      "learning_rate": 4.309876801002297e-06,
      "loss": 0.0471,
      "step": 26300
    },
    {
      "epoch": 0.7860275035050562,
      "grad_norm": 0.0025951031129807234,
      "learning_rate": 4.280046535214629e-06,
      "loss": 0.0412,
      "step": 26350
    },
    {
      "epoch": 0.7875190167944396,
      "grad_norm": 0.4851055145263672,
      "learning_rate": 4.250216269426961e-06,
      "loss": 0.0363,
      "step": 26400
    },
    {
      "epoch": 0.789010530083823,
      "grad_norm": 0.0016780173173174262,
      "learning_rate": 4.220386003639293e-06,
      "loss": 0.0243,
      "step": 26450
    },
    {
      "epoch": 0.7905020433732065,
      "grad_norm": 0.2895536422729492,
      "learning_rate": 4.190555737851625e-06,
      "loss": 0.0562,
      "step": 26500
    },
    {
      "epoch": 0.7919935566625899,
      "grad_norm": 0.01456867903470993,
      "learning_rate": 4.160725472063956e-06,
      "loss": 0.0323,
      "step": 26550
    },
    {
      "epoch": 0.7934850699519733,
      "grad_norm": 0.0008460985263809562,
      "learning_rate": 4.130895206276288e-06,
      "loss": 0.031,
      "step": 26600
    },
    {
      "epoch": 0.7949765832413567,
      "grad_norm": 0.04928872734308243,
      "learning_rate": 4.10106494048862e-06,
      "loss": 0.0268,
      "step": 26650
    },
    {
      "epoch": 0.7964680965307401,
      "grad_norm": 0.0013968246057629585,
      "learning_rate": 4.071234674700951e-06,
      "loss": 0.0629,
      "step": 26700
    },
    {
      "epoch": 0.7979596098201235,
      "grad_norm": 0.01034780964255333,
      "learning_rate": 4.0414044089132835e-06,
      "loss": 0.0311,
      "step": 26750
    },
    {
      "epoch": 0.799451123109507,
      "grad_norm": 0.003487435169517994,
      "learning_rate": 4.011574143125616e-06,
      "loss": 0.0427,
      "step": 26800
    },
    {
      "epoch": 0.8009426363988903,
      "grad_norm": 0.04206092283129692,
      "learning_rate": 3.981743877337948e-06,
      "loss": 0.0488,
      "step": 26850
    },
    {
      "epoch": 0.8024341496882738,
      "grad_norm": 0.19809289276599884,
      "learning_rate": 3.951913611550279e-06,
      "loss": 0.0174,
      "step": 26900
    },
    {
      "epoch": 0.8039256629776571,
      "grad_norm": 0.14013329148292542,
      "learning_rate": 3.922083345762611e-06,
      "loss": 0.017,
      "step": 26950
    },
    {
      "epoch": 0.8054171762670406,
      "grad_norm": 10.884757995605469,
      "learning_rate": 3.892253079974943e-06,
      "loss": 0.0524,
      "step": 27000
    },
    {
      "epoch": 0.8069086895564239,
      "grad_norm": 0.1507737636566162,
      "learning_rate": 3.862422814187275e-06,
      "loss": 0.011,
      "step": 27050
    },
    {
      "epoch": 0.8084002028458074,
      "grad_norm": 0.024292903020977974,
      "learning_rate": 3.8325925483996064e-06,
      "loss": 0.0668,
      "step": 27100
    },
    {
      "epoch": 0.8098917161351907,
      "grad_norm": 1.6350315809249878,
      "learning_rate": 3.802762282611938e-06,
      "loss": 0.0416,
      "step": 27150
    },
    {
      "epoch": 0.8113832294245742,
      "grad_norm": 0.0025311862118542194,
      "learning_rate": 3.77293201682427e-06,
      "loss": 0.0203,
      "step": 27200
    },
    {
      "epoch": 0.8128747427139575,
      "grad_norm": 0.012655414640903473,
      "learning_rate": 3.743101751036602e-06,
      "loss": 0.0146,
      "step": 27250
    },
    {
      "epoch": 0.814366256003341,
      "grad_norm": 0.0016824075719341636,
      "learning_rate": 3.713271485248934e-06,
      "loss": 0.0154,
      "step": 27300
    },
    {
      "epoch": 0.8158577692927244,
      "grad_norm": 0.06360059231519699,
      "learning_rate": 3.6834412194612656e-06,
      "loss": 0.0383,
      "step": 27350
    },
    {
      "epoch": 0.8173492825821078,
      "grad_norm": 0.005387201439589262,
      "learning_rate": 3.6536109536735977e-06,
      "loss": 0.0482,
      "step": 27400
    },
    {
      "epoch": 0.8188407958714912,
      "grad_norm": 0.1977013349533081,
      "learning_rate": 3.6237806878859294e-06,
      "loss": 0.0206,
      "step": 27450
    },
    {
      "epoch": 0.8203323091608746,
      "grad_norm": 0.0006269694422371686,
      "learning_rate": 3.593950422098261e-06,
      "loss": 0.0356,
      "step": 27500
    },
    {
      "epoch": 0.821823822450258,
      "grad_norm": 0.004553081002086401,
      "learning_rate": 3.564120156310593e-06,
      "loss": 0.0312,
      "step": 27550
    },
    {
      "epoch": 0.8233153357396414,
      "grad_norm": 0.011316304095089436,
      "learning_rate": 3.534289890522925e-06,
      "loss": 0.0411,
      "step": 27600
    },
    {
      "epoch": 0.8248068490290249,
      "grad_norm": 0.0011564118321985006,
      "learning_rate": 3.504459624735257e-06,
      "loss": 0.0166,
      "step": 27650
    },
    {
      "epoch": 0.8262983623184083,
      "grad_norm": 0.1616981327533722,
      "learning_rate": 3.474629358947588e-06,
      "loss": 0.082,
      "step": 27700
    },
    {
      "epoch": 0.8277898756077917,
      "grad_norm": 0.10156799852848053,
      "learning_rate": 3.4447990931599203e-06,
      "loss": 0.0272,
      "step": 27750
    },
    {
      "epoch": 0.8292813888971751,
      "grad_norm": 0.16451384127140045,
      "learning_rate": 3.414968827372252e-06,
      "loss": 0.0371,
      "step": 27800
    },
    {
      "epoch": 0.8307729021865585,
      "grad_norm": 17.594738006591797,
      "learning_rate": 3.385138561584584e-06,
      "loss": 0.0465,
      "step": 27850
    },
    {
      "epoch": 0.8322644154759419,
      "grad_norm": 0.0021038318518549204,
      "learning_rate": 3.3553082957969157e-06,
      "loss": 0.0467,
      "step": 27900
    },
    {
      "epoch": 0.8337559287653253,
      "grad_norm": 0.0017672572284936905,
      "learning_rate": 3.325478030009248e-06,
      "loss": 0.0397,
      "step": 27950
    },
    {
      "epoch": 0.8352474420547087,
      "grad_norm": 7.323876857757568,
      "learning_rate": 3.2956477642215795e-06,
      "loss": 0.027,
      "step": 28000
    },
    {
      "epoch": 0.8367389553440922,
      "grad_norm": 0.4286450147628784,
      "learning_rate": 3.2658174984339116e-06,
      "loss": 0.0238,
      "step": 28050
    },
    {
      "epoch": 0.8382304686334755,
      "grad_norm": 0.0013277844991534948,
      "learning_rate": 3.2359872326462432e-06,
      "loss": 0.0145,
      "step": 28100
    },
    {
      "epoch": 0.839721981922859,
      "grad_norm": 0.0022647103760391474,
      "learning_rate": 3.2061569668585753e-06,
      "loss": 0.0266,
      "step": 28150
    },
    {
      "epoch": 0.8412134952122423,
      "grad_norm": 28.248043060302734,
      "learning_rate": 3.176326701070907e-06,
      "loss": 0.0212,
      "step": 28200
    },
    {
      "epoch": 0.8427050085016258,
      "grad_norm": 0.38442379236221313,
      "learning_rate": 3.146496435283239e-06,
      "loss": 0.0333,
      "step": 28250
    },
    {
      "epoch": 0.8441965217910091,
      "grad_norm": 0.0026243063621222973,
      "learning_rate": 3.1166661694955703e-06,
      "loss": 0.0252,
      "step": 28300
    },
    {
      "epoch": 0.8456880350803926,
      "grad_norm": 0.0010870464611798525,
      "learning_rate": 3.086835903707902e-06,
      "loss": 0.0473,
      "step": 28350
    },
    {
      "epoch": 0.8471795483697759,
      "grad_norm": 7.143398761749268,
      "learning_rate": 3.057005637920234e-06,
      "loss": 0.0137,
      "step": 28400
    },
    {
      "epoch": 0.8486710616591594,
      "grad_norm": 16.012622833251953,
      "learning_rate": 3.0271753721325658e-06,
      "loss": 0.063,
      "step": 28450
    },
    {
      "epoch": 0.8501625749485427,
      "grad_norm": 0.0007711662328802049,
      "learning_rate": 2.997345106344898e-06,
      "loss": 0.0097,
      "step": 28500
    },
    {
      "epoch": 0.8516540882379262,
      "grad_norm": 0.0022388885263353586,
      "learning_rate": 2.9675148405572295e-06,
      "loss": 0.0337,
      "step": 28550
    },
    {
      "epoch": 0.8531456015273096,
      "grad_norm": 0.0098479725420475,
      "learning_rate": 2.9376845747695616e-06,
      "loss": 0.0238,
      "step": 28600
    },
    {
      "epoch": 0.854637114816693,
      "grad_norm": 0.007887057960033417,
      "learning_rate": 2.9078543089818933e-06,
      "loss": 0.0817,
      "step": 28650
    },
    {
      "epoch": 0.8561286281060764,
      "grad_norm": 0.0012998632155358791,
      "learning_rate": 2.8780240431942254e-06,
      "loss": 0.0397,
      "step": 28700
    },
    {
      "epoch": 0.8576201413954598,
      "grad_norm": 0.01291658729314804,
      "learning_rate": 2.848193777406557e-06,
      "loss": 0.0515,
      "step": 28750
    },
    {
      "epoch": 0.8591116546848433,
      "grad_norm": 0.00403943657875061,
      "learning_rate": 2.818363511618889e-06,
      "loss": 0.0444,
      "step": 28800
    },
    {
      "epoch": 0.8606031679742266,
      "grad_norm": 0.022908305749297142,
      "learning_rate": 2.7885332458312204e-06,
      "loss": 0.0471,
      "step": 28850
    },
    {
      "epoch": 0.8620946812636101,
      "grad_norm": 0.002851339755579829,
      "learning_rate": 2.758702980043552e-06,
      "loss": 0.0365,
      "step": 28900
    },
    {
      "epoch": 0.8635861945529935,
      "grad_norm": 0.007808572147041559,
      "learning_rate": 2.728872714255884e-06,
      "loss": 0.0394,
      "step": 28950
    },
    {
      "epoch": 0.8650777078423769,
      "grad_norm": 12.971707344055176,
      "learning_rate": 2.699042448468216e-06,
      "loss": 0.0348,
      "step": 29000
    },
    {
      "epoch": 0.8665692211317603,
      "grad_norm": 0.32901036739349365,
      "learning_rate": 2.669212182680548e-06,
      "loss": 0.0595,
      "step": 29050
    },
    {
      "epoch": 0.8680607344211437,
      "grad_norm": 0.002059657359495759,
      "learning_rate": 2.6393819168928796e-06,
      "loss": 0.0283,
      "step": 29100
    },
    {
      "epoch": 0.8695522477105271,
      "grad_norm": 0.10540790855884552,
      "learning_rate": 2.6095516511052117e-06,
      "loss": 0.0582,
      "step": 29150
    },
    {
      "epoch": 0.8710437609999105,
      "grad_norm": 0.09612467139959335,
      "learning_rate": 2.5797213853175434e-06,
      "loss": 0.0281,
      "step": 29200
    },
    {
      "epoch": 0.8725352742892939,
      "grad_norm": 0.01158745028078556,
      "learning_rate": 2.5498911195298754e-06,
      "loss": 0.0414,
      "step": 29250
    },
    {
      "epoch": 0.8740267875786774,
      "grad_norm": 0.10288042575120926,
      "learning_rate": 2.520060853742207e-06,
      "loss": 0.043,
      "step": 29300
    },
    {
      "epoch": 0.8755183008680607,
      "grad_norm": 0.0018720236839726567,
      "learning_rate": 2.4902305879545388e-06,
      "loss": 0.0165,
      "step": 29350
    },
    {
      "epoch": 0.8770098141574442,
      "grad_norm": 0.002004653215408325,
      "learning_rate": 2.460400322166871e-06,
      "loss": 0.0402,
      "step": 29400
    },
    {
      "epoch": 0.8785013274468275,
      "grad_norm": 7.590225696563721,
      "learning_rate": 2.4305700563792025e-06,
      "loss": 0.0294,
      "step": 29450
    },
    {
      "epoch": 0.879992840736211,
      "grad_norm": 16.15267562866211,
      "learning_rate": 2.4007397905915346e-06,
      "loss": 0.04,
      "step": 29500
    },
    {
      "epoch": 0.8814843540255943,
      "grad_norm": 0.0024873760994523764,
      "learning_rate": 2.3709095248038663e-06,
      "loss": 0.0266,
      "step": 29550
    },
    {
      "epoch": 0.8829758673149778,
      "grad_norm": 0.0015841929707676172,
      "learning_rate": 2.341079259016198e-06,
      "loss": 0.0504,
      "step": 29600
    },
    {
      "epoch": 0.8844673806043611,
      "grad_norm": 0.029444005340337753,
      "learning_rate": 2.3112489932285296e-06,
      "loss": 0.0301,
      "step": 29650
    },
    {
      "epoch": 0.8859588938937446,
      "grad_norm": 0.051183633506298065,
      "learning_rate": 2.2814187274408617e-06,
      "loss": 0.0018,
      "step": 29700
    },
    {
      "epoch": 0.887450407183128,
      "grad_norm": 0.09518571197986603,
      "learning_rate": 2.2515884616531934e-06,
      "loss": 0.0267,
      "step": 29750
    },
    {
      "epoch": 0.8889419204725114,
      "grad_norm": 0.01416665967553854,
      "learning_rate": 2.2217581958655255e-06,
      "loss": 0.0106,
      "step": 29800
    },
    {
      "epoch": 0.8904334337618948,
      "grad_norm": 0.014338827691972256,
      "learning_rate": 2.191927930077857e-06,
      "loss": 0.0441,
      "step": 29850
    },
    {
      "epoch": 0.8919249470512782,
      "grad_norm": 9.202417373657227,
      "learning_rate": 2.162097664290189e-06,
      "loss": 0.024,
      "step": 29900
    },
    {
      "epoch": 0.8934164603406617,
      "grad_norm": 0.003021281212568283,
      "learning_rate": 2.132267398502521e-06,
      "loss": 0.0502,
      "step": 29950
    },
    {
      "epoch": 0.894907973630045,
      "grad_norm": 0.00442809471860528,
      "learning_rate": 2.1024371327148526e-06,
      "loss": 0.0164,
      "step": 30000
    },
    {
      "epoch": 0.8963994869194285,
      "grad_norm": 0.024277338758111,
      "learning_rate": 2.0726068669271847e-06,
      "loss": 0.025,
      "step": 30050
    },
    {
      "epoch": 0.8978910002088119,
      "grad_norm": 0.029802868142724037,
      "learning_rate": 2.0427766011395164e-06,
      "loss": 0.032,
      "step": 30100
    },
    {
      "epoch": 0.8993825134981953,
      "grad_norm": 0.04421979561448097,
      "learning_rate": 2.012946335351848e-06,
      "loss": 0.0466,
      "step": 30150
    },
    {
      "epoch": 0.9008740267875787,
      "grad_norm": 0.0059257554821670055,
      "learning_rate": 1.9831160695641797e-06,
      "loss": 0.0318,
      "step": 30200
    },
    {
      "epoch": 0.9023655400769621,
      "grad_norm": 0.04647751525044441,
      "learning_rate": 1.953285803776512e-06,
      "loss": 0.068,
      "step": 30250
    },
    {
      "epoch": 0.9038570533663455,
      "grad_norm": 0.08523064851760864,
      "learning_rate": 1.9234555379888435e-06,
      "loss": 0.0186,
      "step": 30300
    },
    {
      "epoch": 0.9053485666557289,
      "grad_norm": 0.02107948809862137,
      "learning_rate": 1.8936252722011756e-06,
      "loss": 0.0331,
      "step": 30350
    },
    {
      "epoch": 0.9068400799451123,
      "grad_norm": 0.14428764581680298,
      "learning_rate": 1.8637950064135074e-06,
      "loss": 0.0327,
      "step": 30400
    },
    {
      "epoch": 0.9083315932344957,
      "grad_norm": 0.010583469644188881,
      "learning_rate": 1.8339647406258391e-06,
      "loss": 0.0161,
      "step": 30450
    },
    {
      "epoch": 0.9098231065238791,
      "grad_norm": 0.018952198326587677,
      "learning_rate": 1.8041344748381708e-06,
      "loss": 0.0414,
      "step": 30500
    },
    {
      "epoch": 0.9113146198132626,
      "grad_norm": 0.0043806047178804874,
      "learning_rate": 1.7743042090505027e-06,
      "loss": 0.0185,
      "step": 30550
    },
    {
      "epoch": 0.9128061331026459,
      "grad_norm": 0.09665966033935547,
      "learning_rate": 1.7444739432628345e-06,
      "loss": 0.0381,
      "step": 30600
    },
    {
      "epoch": 0.9142976463920294,
      "grad_norm": 0.05761868134140968,
      "learning_rate": 1.7146436774751664e-06,
      "loss": 0.0196,
      "step": 30650
    },
    {
      "epoch": 0.9157891596814127,
      "grad_norm": 0.03031613491475582,
      "learning_rate": 1.6848134116874983e-06,
      "loss": 0.0165,
      "step": 30700
    },
    {
      "epoch": 0.9172806729707962,
      "grad_norm": 0.0012058931170031428,
      "learning_rate": 1.65498314589983e-06,
      "loss": 0.0311,
      "step": 30750
    },
    {
      "epoch": 0.9187721862601795,
      "grad_norm": 0.04014931246638298,
      "learning_rate": 1.6251528801121619e-06,
      "loss": 0.0728,
      "step": 30800
    },
    {
      "epoch": 0.920263699549563,
      "grad_norm": 0.061568889766931534,
      "learning_rate": 1.5953226143244937e-06,
      "loss": 0.0287,
      "step": 30850
    },
    {
      "epoch": 0.9217552128389463,
      "grad_norm": 0.004539665766060352,
      "learning_rate": 1.5654923485368256e-06,
      "loss": 0.0734,
      "step": 30900
    },
    {
      "epoch": 0.9232467261283298,
      "grad_norm": 0.008878995664417744,
      "learning_rate": 1.5356620827491575e-06,
      "loss": 0.0122,
      "step": 30950
    },
    {
      "epoch": 0.9247382394177132,
      "grad_norm": 0.37684720754623413,
      "learning_rate": 1.5058318169614892e-06,
      "loss": 0.0151,
      "step": 31000
    },
    {
      "epoch": 0.9262297527070966,
      "grad_norm": 0.314005583524704,
      "learning_rate": 1.476001551173821e-06,
      "loss": 0.0366,
      "step": 31050
    },
    {
      "epoch": 0.9277212659964801,
      "grad_norm": 0.008267389610409737,
      "learning_rate": 1.446171285386153e-06,
      "loss": 0.0196,
      "step": 31100
    },
    {
      "epoch": 0.9292127792858634,
      "grad_norm": 3.636244058609009,
      "learning_rate": 1.4163410195984848e-06,
      "loss": 0.0364,
      "step": 31150
    },
    {
      "epoch": 0.9307042925752469,
      "grad_norm": 7.535168647766113,
      "learning_rate": 1.3865107538108167e-06,
      "loss": 0.0235,
      "step": 31200
    },
    {
      "epoch": 0.9321958058646302,
      "grad_norm": 8.698648452758789,
      "learning_rate": 1.3566804880231486e-06,
      "loss": 0.0498,
      "step": 31250
    },
    {
      "epoch": 0.9336873191540137,
      "grad_norm": 0.006342500913888216,
      "learning_rate": 1.32685022223548e-06,
      "loss": 0.018,
      "step": 31300
    },
    {
      "epoch": 0.9351788324433971,
      "grad_norm": 0.040794868022203445,
      "learning_rate": 1.297019956447812e-06,
      "loss": 0.0448,
      "step": 31350
    },
    {
      "epoch": 0.9366703457327805,
      "grad_norm": 0.054500605911016464,
      "learning_rate": 1.2671896906601438e-06,
      "loss": 0.0382,
      "step": 31400
    },
    {
      "epoch": 0.9381618590221639,
      "grad_norm": 0.026736857369542122,
      "learning_rate": 1.2373594248724757e-06,
      "loss": 0.0376,
      "step": 31450
    },
    {
      "epoch": 0.9396533723115473,
      "grad_norm": 0.016608159989118576,
      "learning_rate": 1.2075291590848076e-06,
      "loss": 0.0321,
      "step": 31500
    },
    {
      "epoch": 0.9411448856009307,
      "grad_norm": 0.01362062618136406,
      "learning_rate": 1.1776988932971394e-06,
      "loss": 0.0136,
      "step": 31550
    },
    {
      "epoch": 0.9426363988903141,
      "grad_norm": 0.09550758451223373,
      "learning_rate": 1.1478686275094713e-06,
      "loss": 0.026,
      "step": 31600
    },
    {
      "epoch": 0.9441279121796975,
      "grad_norm": 0.06755098700523376,
      "learning_rate": 1.118038361721803e-06,
      "loss": 0.0629,
      "step": 31650
    },
    {
      "epoch": 0.945619425469081,
      "grad_norm": 0.10336238145828247,
      "learning_rate": 1.0882080959341349e-06,
      "loss": 0.0203,
      "step": 31700
    },
    {
      "epoch": 0.9471109387584643,
      "grad_norm": 0.13780760765075684,
      "learning_rate": 1.0583778301464668e-06,
      "loss": 0.021,
      "step": 31750
    },
    {
      "epoch": 0.9486024520478478,
      "grad_norm": 0.11392389237880707,
      "learning_rate": 1.0285475643587984e-06,
      "loss": 0.0116,
      "step": 31800
    },
    {
      "epoch": 0.9500939653372311,
      "grad_norm": 0.0820881724357605,
      "learning_rate": 9.987172985711303e-07,
      "loss": 0.0074,
      "step": 31850
    },
    {
      "epoch": 0.9515854786266146,
      "grad_norm": 38.450279235839844,
      "learning_rate": 9.688870327834622e-07,
      "loss": 0.0296,
      "step": 31900
    },
    {
      "epoch": 0.9530769919159979,
      "grad_norm": 0.005072183441370726,
      "learning_rate": 9.39056766995794e-07,
      "loss": 0.0172,
      "step": 31950
    },
    {
      "epoch": 0.9545685052053814,
      "grad_norm": 0.0025407474022358656,
      "learning_rate": 9.092265012081259e-07,
      "loss": 0.0101,
      "step": 32000
    },
    {
      "epoch": 0.9560600184947647,
      "grad_norm": 0.010836279951035976,
      "learning_rate": 8.793962354204577e-07,
      "loss": 0.0242,
      "step": 32050
    },
    {
      "epoch": 0.9575515317841482,
      "grad_norm": 0.544184684753418,
      "learning_rate": 8.495659696327894e-07,
      "loss": 0.0376,
      "step": 32100
    },
    {
      "epoch": 0.9590430450735316,
      "grad_norm": 0.013461493887007236,
      "learning_rate": 8.197357038451213e-07,
      "loss": 0.0414,
      "step": 32150
    },
    {
      "epoch": 0.960534558362915,
      "grad_norm": 0.008128487505018711,
      "learning_rate": 7.899054380574532e-07,
      "loss": 0.0653,
      "step": 32200
    },
    {
      "epoch": 0.9620260716522985,
      "grad_norm": 0.04133451357483864,
      "learning_rate": 7.600751722697849e-07,
      "loss": 0.0162,
      "step": 32250
    },
    {
      "epoch": 0.9635175849416818,
      "grad_norm": 0.0019109603017568588,
      "learning_rate": 7.302449064821168e-07,
      "loss": 0.0539,
      "step": 32300
    },
    {
      "epoch": 0.9650090982310653,
      "grad_norm": 0.004868833348155022,
      "learning_rate": 7.004146406944487e-07,
      "loss": 0.0131,
      "step": 32350
    },
    {
      "epoch": 0.9665006115204486,
      "grad_norm": 0.01486283726990223,
      "learning_rate": 6.705843749067805e-07,
      "loss": 0.0283,
      "step": 32400
    },
    {
      "epoch": 0.9679921248098321,
      "grad_norm": 0.0032204105518758297,
      "learning_rate": 6.407541091191124e-07,
      "loss": 0.027,
      "step": 32450
    },
    {
      "epoch": 0.9694836380992155,
      "grad_norm": 10.283289909362793,
      "learning_rate": 6.109238433314441e-07,
      "loss": 0.033,
      "step": 32500
    },
    {
      "epoch": 0.9709751513885989,
      "grad_norm": 0.0301223024725914,
      "learning_rate": 5.810935775437759e-07,
      "loss": 0.0304,
      "step": 32550
    },
    {
      "epoch": 0.9724666646779823,
      "grad_norm": 0.0030607450753450394,
      "learning_rate": 5.512633117561078e-07,
      "loss": 0.0177,
      "step": 32600
    },
    {
      "epoch": 0.9739581779673657,
      "grad_norm": 0.0026206776965409517,
      "learning_rate": 5.214330459684396e-07,
      "loss": 0.0231,
      "step": 32650
    },
    {
      "epoch": 0.9754496912567491,
      "grad_norm": 12.018117904663086,
      "learning_rate": 4.916027801807714e-07,
      "loss": 0.0214,
      "step": 32700
    },
    {
      "epoch": 0.9769412045461325,
      "grad_norm": 0.04211168363690376,
      "learning_rate": 4.6177251439310333e-07,
      "loss": 0.0334,
      "step": 32750
    },
    {
      "epoch": 0.9784327178355159,
      "grad_norm": 0.06447812169790268,
      "learning_rate": 4.319422486054351e-07,
      "loss": 0.0233,
      "step": 32800
    },
    {
      "epoch": 0.9799242311248993,
      "grad_norm": 0.0028865719214081764,
      "learning_rate": 4.0211198281776694e-07,
      "loss": 0.0506,
      "step": 32850
    },
    {
      "epoch": 0.9814157444142827,
      "grad_norm": 0.06233469769358635,
      "learning_rate": 3.722817170300988e-07,
      "loss": 0.032,
      "step": 32900
    },
    {
      "epoch": 0.9829072577036662,
      "grad_norm": 0.00877572875469923,
      "learning_rate": 3.424514512424306e-07,
      "loss": 0.0463,
      "step": 32950
    },
    {
      "epoch": 0.9843987709930495,
      "grad_norm": 0.04147382453083992,
      "learning_rate": 3.126211854547624e-07,
      "loss": 0.012,
      "step": 33000
    },
    {
      "epoch": 0.985890284282433,
      "grad_norm": 0.0014670342206954956,
      "learning_rate": 2.8279091966709425e-07,
      "loss": 0.0268,
      "step": 33050
    },
    {
      "epoch": 0.9873817975718163,
      "grad_norm": 0.16739444434642792,
      "learning_rate": 2.529606538794261e-07,
      "loss": 0.0205,
      "step": 33100
    },
    {
      "epoch": 0.9888733108611998,
      "grad_norm": 0.017960771918296814,
      "learning_rate": 2.231303880917579e-07,
      "loss": 0.0322,
      "step": 33150
    },
    {
      "epoch": 0.9903648241505831,
      "grad_norm": 0.07724957168102264,
      "learning_rate": 1.9330012230408976e-07,
      "loss": 0.0435,
      "step": 33200
    },
    {
      "epoch": 0.9918563374399666,
      "grad_norm": 0.0022731362842023373,
      "learning_rate": 1.6346985651642156e-07,
      "loss": 0.0094,
      "step": 33250
    },
    {
      "epoch": 0.99334785072935,
      "grad_norm": 0.0020821697544306517,
      "learning_rate": 1.336395907287534e-07,
      "loss": 0.0378,
      "step": 33300
    },
    {
      "epoch": 0.9948393640187334,
      "grad_norm": 0.032060056924819946,
      "learning_rate": 1.0380932494108523e-07,
      "loss": 0.0291,
      "step": 33350
    },
    {
      "epoch": 0.9963308773081169,
      "grad_norm": 0.07352475076913834,
      "learning_rate": 7.397905915341706e-08,
      "loss": 0.0673,
      "step": 33400
    },
    {
      "epoch": 0.9978223905975002,
      "grad_norm": 0.0018115234561264515,
      "learning_rate": 4.414879336574889e-08,
      "loss": 0.026,
      "step": 33450
    },
    {
      "epoch": 0.9993139038868837,
      "grad_norm": 0.0031156165059655905,
      "learning_rate": 1.4318527578080722e-08,
      "loss": 0.0091,
      "step": 33500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9911190435231378,
      "eval_f1": 0.9911138842868515,
      "eval_loss": 0.03987864404916763,
      "eval_runtime": 239.0334,
      "eval_samples_per_second": 194.55,
      "eval_steps_per_second": 16.215,
      "step": 33523
    }
  ],
  "logging_steps": 50,
  "max_steps": 33523,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.292258054115738e+16,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}

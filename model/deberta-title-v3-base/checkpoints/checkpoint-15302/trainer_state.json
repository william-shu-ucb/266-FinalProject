{
  "best_global_step": 15302,
  "best_metric": 0.9729436127236311,
  "best_model_checkpoint": "/content/drive/MyDrive/MIDS/266/FinalProject/Model/deberta-title-v3-base/checkpoints/checkpoint-15302",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 15302,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032675467259181807,
      "grad_norm": 10.05814266204834,
      "learning_rate": 1.9935956084172005e-05,
      "loss": 0.5953,
      "step": 50
    },
    {
      "epoch": 0.006535093451836361,
      "grad_norm": 5.168361186981201,
      "learning_rate": 1.987060514965364e-05,
      "loss": 0.2777,
      "step": 100
    },
    {
      "epoch": 0.009802640177754542,
      "grad_norm": 11.85062313079834,
      "learning_rate": 1.980525421513528e-05,
      "loss": 0.2613,
      "step": 150
    },
    {
      "epoch": 0.013070186903672723,
      "grad_norm": 4.937117576599121,
      "learning_rate": 1.9739903280616915e-05,
      "loss": 0.1993,
      "step": 200
    },
    {
      "epoch": 0.016337733629590904,
      "grad_norm": 0.6970080733299255,
      "learning_rate": 1.9674552346098548e-05,
      "loss": 0.1544,
      "step": 250
    },
    {
      "epoch": 0.019605280355509083,
      "grad_norm": 9.608049392700195,
      "learning_rate": 1.9609201411580188e-05,
      "loss": 0.185,
      "step": 300
    },
    {
      "epoch": 0.022872827081427266,
      "grad_norm": 6.221789836883545,
      "learning_rate": 1.954385047706182e-05,
      "loss": 0.1472,
      "step": 350
    },
    {
      "epoch": 0.026140373807345445,
      "grad_norm": 12.99481201171875,
      "learning_rate": 1.947849954254346e-05,
      "loss": 0.1705,
      "step": 400
    },
    {
      "epoch": 0.029407920533263625,
      "grad_norm": 1.4952467679977417,
      "learning_rate": 1.9413148608025095e-05,
      "loss": 0.1356,
      "step": 450
    },
    {
      "epoch": 0.03267546725918181,
      "grad_norm": 0.4915948212146759,
      "learning_rate": 1.934779767350673e-05,
      "loss": 0.1282,
      "step": 500
    },
    {
      "epoch": 0.035943013985099984,
      "grad_norm": 4.169810771942139,
      "learning_rate": 1.9282446738988368e-05,
      "loss": 0.1922,
      "step": 550
    },
    {
      "epoch": 0.039210560711018166,
      "grad_norm": 9.09219741821289,
      "learning_rate": 1.9217095804470005e-05,
      "loss": 0.133,
      "step": 600
    },
    {
      "epoch": 0.04247810743693635,
      "grad_norm": 7.147149085998535,
      "learning_rate": 1.915174486995164e-05,
      "loss": 0.1539,
      "step": 650
    },
    {
      "epoch": 0.04574565416285453,
      "grad_norm": 8.616369247436523,
      "learning_rate": 1.9086393935433278e-05,
      "loss": 0.1225,
      "step": 700
    },
    {
      "epoch": 0.04901320088877271,
      "grad_norm": 4.785986423492432,
      "learning_rate": 1.9021043000914915e-05,
      "loss": 0.1559,
      "step": 750
    },
    {
      "epoch": 0.05228074761469089,
      "grad_norm": 6.144496440887451,
      "learning_rate": 1.895569206639655e-05,
      "loss": 0.1391,
      "step": 800
    },
    {
      "epoch": 0.055548294340609074,
      "grad_norm": 5.822957515716553,
      "learning_rate": 1.8890341131878188e-05,
      "loss": 0.1273,
      "step": 850
    },
    {
      "epoch": 0.05881584106652725,
      "grad_norm": 6.7149977684021,
      "learning_rate": 1.8824990197359825e-05,
      "loss": 0.1466,
      "step": 900
    },
    {
      "epoch": 0.06208338779244543,
      "grad_norm": 4.660918712615967,
      "learning_rate": 1.875963926284146e-05,
      "loss": 0.1318,
      "step": 950
    },
    {
      "epoch": 0.06535093451836362,
      "grad_norm": 11.491015434265137,
      "learning_rate": 1.8694288328323095e-05,
      "loss": 0.1365,
      "step": 1000
    },
    {
      "epoch": 0.0686184812442818,
      "grad_norm": 6.446345806121826,
      "learning_rate": 1.8628937393804735e-05,
      "loss": 0.1672,
      "step": 1050
    },
    {
      "epoch": 0.07188602797019997,
      "grad_norm": 5.916680335998535,
      "learning_rate": 1.8563586459286368e-05,
      "loss": 0.1087,
      "step": 1100
    },
    {
      "epoch": 0.07515357469611815,
      "grad_norm": 3.1267261505126953,
      "learning_rate": 1.8498235524768008e-05,
      "loss": 0.1454,
      "step": 1150
    },
    {
      "epoch": 0.07842112142203633,
      "grad_norm": 5.781330108642578,
      "learning_rate": 1.843288459024964e-05,
      "loss": 0.1363,
      "step": 1200
    },
    {
      "epoch": 0.08168866814795452,
      "grad_norm": 6.461471080780029,
      "learning_rate": 1.8367533655731278e-05,
      "loss": 0.1446,
      "step": 1250
    },
    {
      "epoch": 0.0849562148738727,
      "grad_norm": 4.1688690185546875,
      "learning_rate": 1.8302182721212915e-05,
      "loss": 0.1057,
      "step": 1300
    },
    {
      "epoch": 0.08822376159979088,
      "grad_norm": 8.609365463256836,
      "learning_rate": 1.823683178669455e-05,
      "loss": 0.128,
      "step": 1350
    },
    {
      "epoch": 0.09149130832570906,
      "grad_norm": 6.4347052574157715,
      "learning_rate": 1.8171480852176188e-05,
      "loss": 0.1231,
      "step": 1400
    },
    {
      "epoch": 0.09475885505162723,
      "grad_norm": 5.90762996673584,
      "learning_rate": 1.8106129917657825e-05,
      "loss": 0.1274,
      "step": 1450
    },
    {
      "epoch": 0.09802640177754542,
      "grad_norm": 0.8216713666915894,
      "learning_rate": 1.804077898313946e-05,
      "loss": 0.139,
      "step": 1500
    },
    {
      "epoch": 0.1012939485034636,
      "grad_norm": 2.9825973510742188,
      "learning_rate": 1.7975428048621098e-05,
      "loss": 0.1047,
      "step": 1550
    },
    {
      "epoch": 0.10456149522938178,
      "grad_norm": 10.765290260314941,
      "learning_rate": 1.7910077114102735e-05,
      "loss": 0.1068,
      "step": 1600
    },
    {
      "epoch": 0.10782904195529996,
      "grad_norm": 4.823943614959717,
      "learning_rate": 1.7844726179584368e-05,
      "loss": 0.1508,
      "step": 1650
    },
    {
      "epoch": 0.11109658868121815,
      "grad_norm": 6.50714111328125,
      "learning_rate": 1.7779375245066008e-05,
      "loss": 0.1219,
      "step": 1700
    },
    {
      "epoch": 0.11436413540713632,
      "grad_norm": 6.648081302642822,
      "learning_rate": 1.771402431054764e-05,
      "loss": 0.1125,
      "step": 1750
    },
    {
      "epoch": 0.1176316821330545,
      "grad_norm": 4.947824001312256,
      "learning_rate": 1.7648673376029278e-05,
      "loss": 0.1327,
      "step": 1800
    },
    {
      "epoch": 0.12089922885897268,
      "grad_norm": 1.0787265300750732,
      "learning_rate": 1.7583322441510914e-05,
      "loss": 0.1044,
      "step": 1850
    },
    {
      "epoch": 0.12416677558489086,
      "grad_norm": 2.1422922611236572,
      "learning_rate": 1.751797150699255e-05,
      "loss": 0.1045,
      "step": 1900
    },
    {
      "epoch": 0.12743432231080903,
      "grad_norm": 7.211779594421387,
      "learning_rate": 1.7452620572474188e-05,
      "loss": 0.1177,
      "step": 1950
    },
    {
      "epoch": 0.13070186903672723,
      "grad_norm": 4.988970756530762,
      "learning_rate": 1.7387269637955824e-05,
      "loss": 0.1177,
      "step": 2000
    },
    {
      "epoch": 0.1339694157626454,
      "grad_norm": 4.093969345092773,
      "learning_rate": 1.732191870343746e-05,
      "loss": 0.1155,
      "step": 2050
    },
    {
      "epoch": 0.1372369624885636,
      "grad_norm": 8.532265663146973,
      "learning_rate": 1.7256567768919098e-05,
      "loss": 0.1191,
      "step": 2100
    },
    {
      "epoch": 0.14050450921448177,
      "grad_norm": 7.828137397766113,
      "learning_rate": 1.719121683440073e-05,
      "loss": 0.1113,
      "step": 2150
    },
    {
      "epoch": 0.14377205594039993,
      "grad_norm": 6.9954915046691895,
      "learning_rate": 1.712586589988237e-05,
      "loss": 0.1257,
      "step": 2200
    },
    {
      "epoch": 0.14703960266631813,
      "grad_norm": 9.308893203735352,
      "learning_rate": 1.7060514965364004e-05,
      "loss": 0.0979,
      "step": 2250
    },
    {
      "epoch": 0.1503071493922363,
      "grad_norm": 2.055004119873047,
      "learning_rate": 1.6995164030845644e-05,
      "loss": 0.1202,
      "step": 2300
    },
    {
      "epoch": 0.1535746961181545,
      "grad_norm": 3.5795586109161377,
      "learning_rate": 1.6929813096327278e-05,
      "loss": 0.1252,
      "step": 2350
    },
    {
      "epoch": 0.15684224284407267,
      "grad_norm": 3.140366792678833,
      "learning_rate": 1.6864462161808914e-05,
      "loss": 0.0967,
      "step": 2400
    },
    {
      "epoch": 0.16010978956999086,
      "grad_norm": 0.5440654158592224,
      "learning_rate": 1.679911122729055e-05,
      "loss": 0.0986,
      "step": 2450
    },
    {
      "epoch": 0.16337733629590903,
      "grad_norm": 0.9322034120559692,
      "learning_rate": 1.6733760292772188e-05,
      "loss": 0.1281,
      "step": 2500
    },
    {
      "epoch": 0.1666448830218272,
      "grad_norm": 6.235538005828857,
      "learning_rate": 1.6668409358253824e-05,
      "loss": 0.0991,
      "step": 2550
    },
    {
      "epoch": 0.1699124297477454,
      "grad_norm": 3.683302879333496,
      "learning_rate": 1.660305842373546e-05,
      "loss": 0.1256,
      "step": 2600
    },
    {
      "epoch": 0.17317997647366357,
      "grad_norm": 3.7723937034606934,
      "learning_rate": 1.6537707489217098e-05,
      "loss": 0.1037,
      "step": 2650
    },
    {
      "epoch": 0.17644752319958176,
      "grad_norm": 5.953339576721191,
      "learning_rate": 1.6472356554698734e-05,
      "loss": 0.1026,
      "step": 2700
    },
    {
      "epoch": 0.17971506992549993,
      "grad_norm": 4.587212085723877,
      "learning_rate": 1.640700562018037e-05,
      "loss": 0.1119,
      "step": 2750
    },
    {
      "epoch": 0.18298261665141813,
      "grad_norm": 8.983537673950195,
      "learning_rate": 1.6341654685662008e-05,
      "loss": 0.111,
      "step": 2800
    },
    {
      "epoch": 0.1862501633773363,
      "grad_norm": 1.9680252075195312,
      "learning_rate": 1.6276303751143644e-05,
      "loss": 0.111,
      "step": 2850
    },
    {
      "epoch": 0.18951771010325447,
      "grad_norm": 0.06123806908726692,
      "learning_rate": 1.6210952816625277e-05,
      "loss": 0.0993,
      "step": 2900
    },
    {
      "epoch": 0.19278525682917266,
      "grad_norm": 2.387845516204834,
      "learning_rate": 1.6145601882106917e-05,
      "loss": 0.1157,
      "step": 2950
    },
    {
      "epoch": 0.19605280355509083,
      "grad_norm": 2.0730950832366943,
      "learning_rate": 1.608025094758855e-05,
      "loss": 0.1092,
      "step": 3000
    },
    {
      "epoch": 0.19932035028100903,
      "grad_norm": 7.416567325592041,
      "learning_rate": 1.601490001307019e-05,
      "loss": 0.1022,
      "step": 3050
    },
    {
      "epoch": 0.2025878970069272,
      "grad_norm": 2.2251198291778564,
      "learning_rate": 1.5949549078551824e-05,
      "loss": 0.1006,
      "step": 3100
    },
    {
      "epoch": 0.20585544373284537,
      "grad_norm": 1.5990967750549316,
      "learning_rate": 1.588419814403346e-05,
      "loss": 0.0911,
      "step": 3150
    },
    {
      "epoch": 0.20912299045876356,
      "grad_norm": 3.8619349002838135,
      "learning_rate": 1.5818847209515097e-05,
      "loss": 0.1167,
      "step": 3200
    },
    {
      "epoch": 0.21239053718468173,
      "grad_norm": 1.1760927438735962,
      "learning_rate": 1.5753496274996734e-05,
      "loss": 0.1089,
      "step": 3250
    },
    {
      "epoch": 0.21565808391059993,
      "grad_norm": 4.504530906677246,
      "learning_rate": 1.568814534047837e-05,
      "loss": 0.1072,
      "step": 3300
    },
    {
      "epoch": 0.2189256306365181,
      "grad_norm": 4.626245498657227,
      "learning_rate": 1.5622794405960007e-05,
      "loss": 0.097,
      "step": 3350
    },
    {
      "epoch": 0.2221931773624363,
      "grad_norm": 1.4762474298477173,
      "learning_rate": 1.555744347144164e-05,
      "loss": 0.0979,
      "step": 3400
    },
    {
      "epoch": 0.22546072408835446,
      "grad_norm": 4.824375629425049,
      "learning_rate": 1.549209253692328e-05,
      "loss": 0.1174,
      "step": 3450
    },
    {
      "epoch": 0.22872827081427263,
      "grad_norm": 8.078235626220703,
      "learning_rate": 1.5426741602404914e-05,
      "loss": 0.1134,
      "step": 3500
    },
    {
      "epoch": 0.23199581754019083,
      "grad_norm": 4.797275066375732,
      "learning_rate": 1.536139066788655e-05,
      "loss": 0.0926,
      "step": 3550
    },
    {
      "epoch": 0.235263364266109,
      "grad_norm": 2.6927571296691895,
      "learning_rate": 1.5296039733368187e-05,
      "loss": 0.1012,
      "step": 3600
    },
    {
      "epoch": 0.2385309109920272,
      "grad_norm": 5.658402919769287,
      "learning_rate": 1.5230688798849824e-05,
      "loss": 0.0849,
      "step": 3650
    },
    {
      "epoch": 0.24179845771794536,
      "grad_norm": 5.070897102355957,
      "learning_rate": 1.5165337864331462e-05,
      "loss": 0.0886,
      "step": 3700
    },
    {
      "epoch": 0.24506600444386356,
      "grad_norm": 4.189244270324707,
      "learning_rate": 1.5099986929813097e-05,
      "loss": 0.111,
      "step": 3750
    },
    {
      "epoch": 0.24833355116978173,
      "grad_norm": 3.3653528690338135,
      "learning_rate": 1.5034635995294732e-05,
      "loss": 0.0977,
      "step": 3800
    },
    {
      "epoch": 0.2516010978956999,
      "grad_norm": 7.005941390991211,
      "learning_rate": 1.496928506077637e-05,
      "loss": 0.0986,
      "step": 3850
    },
    {
      "epoch": 0.25486864462161807,
      "grad_norm": 5.142505645751953,
      "learning_rate": 1.4903934126258005e-05,
      "loss": 0.1039,
      "step": 3900
    },
    {
      "epoch": 0.2581361913475363,
      "grad_norm": 2.3624491691589355,
      "learning_rate": 1.4838583191739644e-05,
      "loss": 0.1278,
      "step": 3950
    },
    {
      "epoch": 0.26140373807345446,
      "grad_norm": 5.563679218292236,
      "learning_rate": 1.4773232257221279e-05,
      "loss": 0.1022,
      "step": 4000
    },
    {
      "epoch": 0.26467128479937263,
      "grad_norm": 2.671245813369751,
      "learning_rate": 1.4707881322702915e-05,
      "loss": 0.1035,
      "step": 4050
    },
    {
      "epoch": 0.2679388315252908,
      "grad_norm": 4.737722396850586,
      "learning_rate": 1.4642530388184552e-05,
      "loss": 0.1008,
      "step": 4100
    },
    {
      "epoch": 0.27120637825120897,
      "grad_norm": 5.657132625579834,
      "learning_rate": 1.4577179453666189e-05,
      "loss": 0.0823,
      "step": 4150
    },
    {
      "epoch": 0.2744739249771272,
      "grad_norm": 11.066166877746582,
      "learning_rate": 1.4511828519147825e-05,
      "loss": 0.0884,
      "step": 4200
    },
    {
      "epoch": 0.27774147170304536,
      "grad_norm": 4.123967170715332,
      "learning_rate": 1.4446477584629462e-05,
      "loss": 0.0981,
      "step": 4250
    },
    {
      "epoch": 0.28100901842896353,
      "grad_norm": 0.447341650724411,
      "learning_rate": 1.4381126650111097e-05,
      "loss": 0.1063,
      "step": 4300
    },
    {
      "epoch": 0.2842765651548817,
      "grad_norm": 1.3197166919708252,
      "learning_rate": 1.4315775715592735e-05,
      "loss": 0.0773,
      "step": 4350
    },
    {
      "epoch": 0.28754411188079987,
      "grad_norm": 2.8498728275299072,
      "learning_rate": 1.425042478107437e-05,
      "loss": 0.1164,
      "step": 4400
    },
    {
      "epoch": 0.2908116586067181,
      "grad_norm": 7.890923500061035,
      "learning_rate": 1.4185073846556009e-05,
      "loss": 0.1122,
      "step": 4450
    },
    {
      "epoch": 0.29407920533263626,
      "grad_norm": 7.792639255523682,
      "learning_rate": 1.4119722912037644e-05,
      "loss": 0.0958,
      "step": 4500
    },
    {
      "epoch": 0.29734675205855443,
      "grad_norm": 0.8032541871070862,
      "learning_rate": 1.4054371977519279e-05,
      "loss": 0.0992,
      "step": 4550
    },
    {
      "epoch": 0.3006142987844726,
      "grad_norm": 0.2957516312599182,
      "learning_rate": 1.3989021043000917e-05,
      "loss": 0.0763,
      "step": 4600
    },
    {
      "epoch": 0.3038818455103908,
      "grad_norm": 5.021566390991211,
      "learning_rate": 1.3923670108482552e-05,
      "loss": 0.0978,
      "step": 4650
    },
    {
      "epoch": 0.307149392236309,
      "grad_norm": 2.4777257442474365,
      "learning_rate": 1.385831917396419e-05,
      "loss": 0.1128,
      "step": 4700
    },
    {
      "epoch": 0.31041693896222716,
      "grad_norm": 3.580866575241089,
      "learning_rate": 1.3792968239445825e-05,
      "loss": 0.0978,
      "step": 4750
    },
    {
      "epoch": 0.31368448568814533,
      "grad_norm": 7.210819244384766,
      "learning_rate": 1.372761730492746e-05,
      "loss": 0.0901,
      "step": 4800
    },
    {
      "epoch": 0.3169520324140635,
      "grad_norm": 0.13493509590625763,
      "learning_rate": 1.3662266370409099e-05,
      "loss": 0.0841,
      "step": 4850
    },
    {
      "epoch": 0.3202195791399817,
      "grad_norm": 0.6339049339294434,
      "learning_rate": 1.3596915435890733e-05,
      "loss": 0.092,
      "step": 4900
    },
    {
      "epoch": 0.3234871258658999,
      "grad_norm": 7.511412620544434,
      "learning_rate": 1.3531564501372372e-05,
      "loss": 0.0936,
      "step": 4950
    },
    {
      "epoch": 0.32675467259181806,
      "grad_norm": 3.871736526489258,
      "learning_rate": 1.3466213566854007e-05,
      "loss": 0.1053,
      "step": 5000
    },
    {
      "epoch": 0.33002221931773623,
      "grad_norm": 4.115597724914551,
      "learning_rate": 1.3400862632335643e-05,
      "loss": 0.0863,
      "step": 5050
    },
    {
      "epoch": 0.3332897660436544,
      "grad_norm": 2.227874755859375,
      "learning_rate": 1.333551169781728e-05,
      "loss": 0.1121,
      "step": 5100
    },
    {
      "epoch": 0.3365573127695726,
      "grad_norm": 2.5069797039031982,
      "learning_rate": 1.3270160763298917e-05,
      "loss": 0.0894,
      "step": 5150
    },
    {
      "epoch": 0.3398248594954908,
      "grad_norm": 3.470179557800293,
      "learning_rate": 1.3204809828780553e-05,
      "loss": 0.1126,
      "step": 5200
    },
    {
      "epoch": 0.34309240622140896,
      "grad_norm": 2.664541482925415,
      "learning_rate": 1.313945889426219e-05,
      "loss": 0.0979,
      "step": 5250
    },
    {
      "epoch": 0.34635995294732713,
      "grad_norm": 10.654399871826172,
      "learning_rate": 1.3074107959743825e-05,
      "loss": 0.0897,
      "step": 5300
    },
    {
      "epoch": 0.3496274996732453,
      "grad_norm": 0.07657774537801743,
      "learning_rate": 1.3008757025225462e-05,
      "loss": 0.0802,
      "step": 5350
    },
    {
      "epoch": 0.3528950463991635,
      "grad_norm": 3.1668546199798584,
      "learning_rate": 1.2943406090707098e-05,
      "loss": 0.105,
      "step": 5400
    },
    {
      "epoch": 0.3561625931250817,
      "grad_norm": 2.9737632274627686,
      "learning_rate": 1.2878055156188733e-05,
      "loss": 0.0927,
      "step": 5450
    },
    {
      "epoch": 0.35943013985099986,
      "grad_norm": 2.770864725112915,
      "learning_rate": 1.2812704221670372e-05,
      "loss": 0.0965,
      "step": 5500
    },
    {
      "epoch": 0.36269768657691803,
      "grad_norm": 2.8647007942199707,
      "learning_rate": 1.2747353287152007e-05,
      "loss": 0.0981,
      "step": 5550
    },
    {
      "epoch": 0.36596523330283626,
      "grad_norm": 3.146300792694092,
      "learning_rate": 1.2682002352633645e-05,
      "loss": 0.0948,
      "step": 5600
    },
    {
      "epoch": 0.3692327800287544,
      "grad_norm": 0.6109248399734497,
      "learning_rate": 1.261665141811528e-05,
      "loss": 0.0999,
      "step": 5650
    },
    {
      "epoch": 0.3725003267546726,
      "grad_norm": 1.8067357540130615,
      "learning_rate": 1.2551300483596915e-05,
      "loss": 0.0989,
      "step": 5700
    },
    {
      "epoch": 0.37576787348059076,
      "grad_norm": 1.113479495048523,
      "learning_rate": 1.2485949549078553e-05,
      "loss": 0.0976,
      "step": 5750
    },
    {
      "epoch": 0.37903542020650893,
      "grad_norm": 7.100080490112305,
      "learning_rate": 1.2420598614560188e-05,
      "loss": 0.0829,
      "step": 5800
    },
    {
      "epoch": 0.38230296693242716,
      "grad_norm": 0.24918225407600403,
      "learning_rate": 1.2355247680041827e-05,
      "loss": 0.0748,
      "step": 5850
    },
    {
      "epoch": 0.3855705136583453,
      "grad_norm": 5.0218915939331055,
      "learning_rate": 1.2289896745523461e-05,
      "loss": 0.0888,
      "step": 5900
    },
    {
      "epoch": 0.3888380603842635,
      "grad_norm": 4.299153804779053,
      "learning_rate": 1.2224545811005098e-05,
      "loss": 0.1036,
      "step": 5950
    },
    {
      "epoch": 0.39210560711018166,
      "grad_norm": 5.682110786437988,
      "learning_rate": 1.2159194876486735e-05,
      "loss": 0.0847,
      "step": 6000
    },
    {
      "epoch": 0.39537315383609983,
      "grad_norm": 5.748256206512451,
      "learning_rate": 1.2093843941968371e-05,
      "loss": 0.0976,
      "step": 6050
    },
    {
      "epoch": 0.39864070056201806,
      "grad_norm": 0.6502841711044312,
      "learning_rate": 1.2028493007450008e-05,
      "loss": 0.0813,
      "step": 6100
    },
    {
      "epoch": 0.4019082472879362,
      "grad_norm": 2.569955348968506,
      "learning_rate": 1.1963142072931643e-05,
      "loss": 0.085,
      "step": 6150
    },
    {
      "epoch": 0.4051757940138544,
      "grad_norm": 4.756560802459717,
      "learning_rate": 1.189779113841328e-05,
      "loss": 0.0911,
      "step": 6200
    },
    {
      "epoch": 0.40844334073977256,
      "grad_norm": 4.355772018432617,
      "learning_rate": 1.1832440203894916e-05,
      "loss": 0.0775,
      "step": 6250
    },
    {
      "epoch": 0.41171088746569073,
      "grad_norm": 6.05305814743042,
      "learning_rate": 1.1767089269376553e-05,
      "loss": 0.0876,
      "step": 6300
    },
    {
      "epoch": 0.41497843419160896,
      "grad_norm": 6.279592037200928,
      "learning_rate": 1.170173833485819e-05,
      "loss": 0.0924,
      "step": 6350
    },
    {
      "epoch": 0.4182459809175271,
      "grad_norm": 1.689228892326355,
      "learning_rate": 1.1636387400339826e-05,
      "loss": 0.0833,
      "step": 6400
    },
    {
      "epoch": 0.4215135276434453,
      "grad_norm": 2.7464847564697266,
      "learning_rate": 1.1571036465821461e-05,
      "loss": 0.0774,
      "step": 6450
    },
    {
      "epoch": 0.42478107436936346,
      "grad_norm": 5.056154251098633,
      "learning_rate": 1.15056855313031e-05,
      "loss": 0.1022,
      "step": 6500
    },
    {
      "epoch": 0.4280486210952817,
      "grad_norm": 0.5041815042495728,
      "learning_rate": 1.1440334596784735e-05,
      "loss": 0.0892,
      "step": 6550
    },
    {
      "epoch": 0.43131616782119986,
      "grad_norm": 0.16869887709617615,
      "learning_rate": 1.1374983662266373e-05,
      "loss": 0.078,
      "step": 6600
    },
    {
      "epoch": 0.434583714547118,
      "grad_norm": 8.314708709716797,
      "learning_rate": 1.1309632727748008e-05,
      "loss": 0.1108,
      "step": 6650
    },
    {
      "epoch": 0.4378512612730362,
      "grad_norm": 5.331460952758789,
      "learning_rate": 1.1244281793229643e-05,
      "loss": 0.082,
      "step": 6700
    },
    {
      "epoch": 0.44111880799895437,
      "grad_norm": 6.965642929077148,
      "learning_rate": 1.1178930858711281e-05,
      "loss": 0.0946,
      "step": 6750
    },
    {
      "epoch": 0.4443863547248726,
      "grad_norm": 3.066025972366333,
      "learning_rate": 1.1113579924192916e-05,
      "loss": 0.1002,
      "step": 6800
    },
    {
      "epoch": 0.44765390145079076,
      "grad_norm": 3.0649101734161377,
      "learning_rate": 1.1048228989674555e-05,
      "loss": 0.0943,
      "step": 6850
    },
    {
      "epoch": 0.45092144817670893,
      "grad_norm": 5.522931098937988,
      "learning_rate": 1.098287805515619e-05,
      "loss": 0.1063,
      "step": 6900
    },
    {
      "epoch": 0.4541889949026271,
      "grad_norm": 4.021920680999756,
      "learning_rate": 1.0917527120637824e-05,
      "loss": 0.0563,
      "step": 6950
    },
    {
      "epoch": 0.45745654162854527,
      "grad_norm": 3.4228827953338623,
      "learning_rate": 1.0852176186119463e-05,
      "loss": 0.081,
      "step": 7000
    },
    {
      "epoch": 0.4607240883544635,
      "grad_norm": 4.478036880493164,
      "learning_rate": 1.0786825251601098e-05,
      "loss": 0.1075,
      "step": 7050
    },
    {
      "epoch": 0.46399163508038166,
      "grad_norm": 6.155488967895508,
      "learning_rate": 1.0721474317082736e-05,
      "loss": 0.0751,
      "step": 7100
    },
    {
      "epoch": 0.46725918180629983,
      "grad_norm": 5.359973907470703,
      "learning_rate": 1.0656123382564371e-05,
      "loss": 0.0875,
      "step": 7150
    },
    {
      "epoch": 0.470526728532218,
      "grad_norm": 2.2654480934143066,
      "learning_rate": 1.0590772448046008e-05,
      "loss": 0.0792,
      "step": 7200
    },
    {
      "epoch": 0.47379427525813617,
      "grad_norm": 3.706169843673706,
      "learning_rate": 1.0525421513527644e-05,
      "loss": 0.0976,
      "step": 7250
    },
    {
      "epoch": 0.4770618219840544,
      "grad_norm": 7.79829216003418,
      "learning_rate": 1.0460070579009281e-05,
      "loss": 0.0908,
      "step": 7300
    },
    {
      "epoch": 0.48032936870997256,
      "grad_norm": 6.191473007202148,
      "learning_rate": 1.0394719644490916e-05,
      "loss": 0.0911,
      "step": 7350
    },
    {
      "epoch": 0.48359691543589073,
      "grad_norm": 0.46124762296676636,
      "learning_rate": 1.0329368709972554e-05,
      "loss": 0.0853,
      "step": 7400
    },
    {
      "epoch": 0.4868644621618089,
      "grad_norm": 0.16327786445617676,
      "learning_rate": 1.026401777545419e-05,
      "loss": 0.0746,
      "step": 7450
    },
    {
      "epoch": 0.4901320088877271,
      "grad_norm": 4.1350603103637695,
      "learning_rate": 1.0198666840935828e-05,
      "loss": 0.0894,
      "step": 7500
    },
    {
      "epoch": 0.4933995556136453,
      "grad_norm": 7.077062129974365,
      "learning_rate": 1.0133315906417463e-05,
      "loss": 0.0765,
      "step": 7550
    },
    {
      "epoch": 0.49666710233956346,
      "grad_norm": 8.17310619354248,
      "learning_rate": 1.0067964971899098e-05,
      "loss": 0.0767,
      "step": 7600
    },
    {
      "epoch": 0.49993464906548163,
      "grad_norm": 6.569487571716309,
      "learning_rate": 1.0002614037380736e-05,
      "loss": 0.0761,
      "step": 7650
    },
    {
      "epoch": 0.5032021957913998,
      "grad_norm": 0.22350871562957764,
      "learning_rate": 9.937263102862373e-06,
      "loss": 0.0759,
      "step": 7700
    },
    {
      "epoch": 0.506469742517318,
      "grad_norm": 2.74735951423645,
      "learning_rate": 9.871912168344008e-06,
      "loss": 0.0827,
      "step": 7750
    },
    {
      "epoch": 0.5097372892432361,
      "grad_norm": 3.6328258514404297,
      "learning_rate": 9.806561233825644e-06,
      "loss": 0.0657,
      "step": 7800
    },
    {
      "epoch": 0.5130048359691544,
      "grad_norm": 4.68410062789917,
      "learning_rate": 9.741210299307281e-06,
      "loss": 0.0876,
      "step": 7850
    },
    {
      "epoch": 0.5162723826950726,
      "grad_norm": 0.3294943869113922,
      "learning_rate": 9.675859364788918e-06,
      "loss": 0.0762,
      "step": 7900
    },
    {
      "epoch": 0.5195399294209907,
      "grad_norm": 7.478172779083252,
      "learning_rate": 9.610508430270553e-06,
      "loss": 0.1016,
      "step": 7950
    },
    {
      "epoch": 0.5228074761469089,
      "grad_norm": 0.4534187912940979,
      "learning_rate": 9.54515749575219e-06,
      "loss": 0.0888,
      "step": 8000
    },
    {
      "epoch": 0.526075022872827,
      "grad_norm": 4.29599666595459,
      "learning_rate": 9.479806561233826e-06,
      "loss": 0.0782,
      "step": 8050
    },
    {
      "epoch": 0.5293425695987453,
      "grad_norm": 7.49881649017334,
      "learning_rate": 9.414455626715462e-06,
      "loss": 0.0975,
      "step": 8100
    },
    {
      "epoch": 0.5326101163246635,
      "grad_norm": 1.2435848712921143,
      "learning_rate": 9.349104692197099e-06,
      "loss": 0.073,
      "step": 8150
    },
    {
      "epoch": 0.5358776630505816,
      "grad_norm": 0.39015987515449524,
      "learning_rate": 9.283753757678736e-06,
      "loss": 0.0723,
      "step": 8200
    },
    {
      "epoch": 0.5391452097764998,
      "grad_norm": 3.494256019592285,
      "learning_rate": 9.218402823160372e-06,
      "loss": 0.0776,
      "step": 8250
    },
    {
      "epoch": 0.5424127565024179,
      "grad_norm": 8.177411079406738,
      "learning_rate": 9.153051888642009e-06,
      "loss": 0.0759,
      "step": 8300
    },
    {
      "epoch": 0.5456803032283362,
      "grad_norm": 7.052028179168701,
      "learning_rate": 9.087700954123646e-06,
      "loss": 0.0734,
      "step": 8350
    },
    {
      "epoch": 0.5489478499542544,
      "grad_norm": 3.664052724838257,
      "learning_rate": 9.022350019605282e-06,
      "loss": 0.0817,
      "step": 8400
    },
    {
      "epoch": 0.5522153966801725,
      "grad_norm": 4.186651229858398,
      "learning_rate": 8.956999085086917e-06,
      "loss": 0.0834,
      "step": 8450
    },
    {
      "epoch": 0.5554829434060907,
      "grad_norm": 3.7174737453460693,
      "learning_rate": 8.891648150568554e-06,
      "loss": 0.0829,
      "step": 8500
    },
    {
      "epoch": 0.5587504901320088,
      "grad_norm": 2.3426060676574707,
      "learning_rate": 8.82629721605019e-06,
      "loss": 0.0995,
      "step": 8550
    },
    {
      "epoch": 0.5620180368579271,
      "grad_norm": 3.8531172275543213,
      "learning_rate": 8.760946281531827e-06,
      "loss": 0.0869,
      "step": 8600
    },
    {
      "epoch": 0.5652855835838453,
      "grad_norm": 3.1434381008148193,
      "learning_rate": 8.695595347013464e-06,
      "loss": 0.068,
      "step": 8650
    },
    {
      "epoch": 0.5685531303097634,
      "grad_norm": 0.5009814500808716,
      "learning_rate": 8.630244412495099e-06,
      "loss": 0.1004,
      "step": 8700
    },
    {
      "epoch": 0.5718206770356816,
      "grad_norm": 2.914489507675171,
      "learning_rate": 8.564893477976736e-06,
      "loss": 0.0818,
      "step": 8750
    },
    {
      "epoch": 0.5750882237615997,
      "grad_norm": 0.4083257019519806,
      "learning_rate": 8.499542543458372e-06,
      "loss": 0.071,
      "step": 8800
    },
    {
      "epoch": 0.578355770487518,
      "grad_norm": 3.1910970211029053,
      "learning_rate": 8.434191608940009e-06,
      "loss": 0.0845,
      "step": 8850
    },
    {
      "epoch": 0.5816233172134362,
      "grad_norm": 3.3334546089172363,
      "learning_rate": 8.368840674421644e-06,
      "loss": 0.0812,
      "step": 8900
    },
    {
      "epoch": 0.5848908639393543,
      "grad_norm": 3.299359083175659,
      "learning_rate": 8.30348973990328e-06,
      "loss": 0.0758,
      "step": 8950
    },
    {
      "epoch": 0.5881584106652725,
      "grad_norm": 2.603132963180542,
      "learning_rate": 8.238138805384917e-06,
      "loss": 0.0852,
      "step": 9000
    },
    {
      "epoch": 0.5914259573911907,
      "grad_norm": 0.8150787353515625,
      "learning_rate": 8.172787870866554e-06,
      "loss": 0.0888,
      "step": 9050
    },
    {
      "epoch": 0.5946935041171089,
      "grad_norm": 4.482330322265625,
      "learning_rate": 8.10743693634819e-06,
      "loss": 0.0872,
      "step": 9100
    },
    {
      "epoch": 0.5979610508430271,
      "grad_norm": 4.891571044921875,
      "learning_rate": 8.042086001829827e-06,
      "loss": 0.0791,
      "step": 9150
    },
    {
      "epoch": 0.6012285975689452,
      "grad_norm": 3.0616934299468994,
      "learning_rate": 7.976735067311464e-06,
      "loss": 0.0747,
      "step": 9200
    },
    {
      "epoch": 0.6044961442948634,
      "grad_norm": 5.77987003326416,
      "learning_rate": 7.911384132793099e-06,
      "loss": 0.0861,
      "step": 9250
    },
    {
      "epoch": 0.6077636910207816,
      "grad_norm": 0.3812522888183594,
      "learning_rate": 7.846033198274735e-06,
      "loss": 0.0617,
      "step": 9300
    },
    {
      "epoch": 0.6110312377466998,
      "grad_norm": 1.4068219661712646,
      "learning_rate": 7.780682263756372e-06,
      "loss": 0.0712,
      "step": 9350
    },
    {
      "epoch": 0.614298784472618,
      "grad_norm": 4.535790920257568,
      "learning_rate": 7.715331329238009e-06,
      "loss": 0.0886,
      "step": 9400
    },
    {
      "epoch": 0.6175663311985361,
      "grad_norm": 5.263490676879883,
      "learning_rate": 7.649980394719645e-06,
      "loss": 0.0805,
      "step": 9450
    },
    {
      "epoch": 0.6208338779244543,
      "grad_norm": 5.7918925285339355,
      "learning_rate": 7.584629460201281e-06,
      "loss": 0.087,
      "step": 9500
    },
    {
      "epoch": 0.6241014246503725,
      "grad_norm": 5.837976455688477,
      "learning_rate": 7.519278525682918e-06,
      "loss": 0.1041,
      "step": 9550
    },
    {
      "epoch": 0.6273689713762907,
      "grad_norm": 7.677437782287598,
      "learning_rate": 7.4539275911645545e-06,
      "loss": 0.0742,
      "step": 9600
    },
    {
      "epoch": 0.6306365181022089,
      "grad_norm": 4.048445224761963,
      "learning_rate": 7.38857665664619e-06,
      "loss": 0.074,
      "step": 9650
    },
    {
      "epoch": 0.633904064828127,
      "grad_norm": 2.2105181217193604,
      "learning_rate": 7.323225722127827e-06,
      "loss": 0.0784,
      "step": 9700
    },
    {
      "epoch": 0.6371716115540452,
      "grad_norm": 0.34249797463417053,
      "learning_rate": 7.257874787609464e-06,
      "loss": 0.0713,
      "step": 9750
    },
    {
      "epoch": 0.6404391582799634,
      "grad_norm": 4.746074676513672,
      "learning_rate": 7.1925238530911e-06,
      "loss": 0.083,
      "step": 9800
    },
    {
      "epoch": 0.6437067050058816,
      "grad_norm": 10.0003662109375,
      "learning_rate": 7.127172918572735e-06,
      "loss": 0.09,
      "step": 9850
    },
    {
      "epoch": 0.6469742517317998,
      "grad_norm": 3.029620885848999,
      "learning_rate": 7.061821984054372e-06,
      "loss": 0.0765,
      "step": 9900
    },
    {
      "epoch": 0.6502417984577179,
      "grad_norm": 0.27355721592903137,
      "learning_rate": 6.9964710495360086e-06,
      "loss": 0.0862,
      "step": 9950
    },
    {
      "epoch": 0.6535093451836361,
      "grad_norm": 0.9678407311439514,
      "learning_rate": 6.931120115017645e-06,
      "loss": 0.0801,
      "step": 10000
    },
    {
      "epoch": 0.6567768919095544,
      "grad_norm": 1.8787200450897217,
      "learning_rate": 6.865769180499282e-06,
      "loss": 0.0993,
      "step": 10050
    },
    {
      "epoch": 0.6600444386354725,
      "grad_norm": 1.5947226285934448,
      "learning_rate": 6.800418245980918e-06,
      "loss": 0.0707,
      "step": 10100
    },
    {
      "epoch": 0.6633119853613907,
      "grad_norm": 2.855851888656616,
      "learning_rate": 6.735067311462554e-06,
      "loss": 0.0729,
      "step": 10150
    },
    {
      "epoch": 0.6665795320873088,
      "grad_norm": 3.718816041946411,
      "learning_rate": 6.669716376944191e-06,
      "loss": 0.084,
      "step": 10200
    },
    {
      "epoch": 0.669847078813227,
      "grad_norm": 3.9456262588500977,
      "learning_rate": 6.604365442425828e-06,
      "loss": 0.0853,
      "step": 10250
    },
    {
      "epoch": 0.6731146255391453,
      "grad_norm": 6.8031229972839355,
      "learning_rate": 6.539014507907464e-06,
      "loss": 0.0806,
      "step": 10300
    },
    {
      "epoch": 0.6763821722650634,
      "grad_norm": 6.286864757537842,
      "learning_rate": 6.473663573389099e-06,
      "loss": 0.0662,
      "step": 10350
    },
    {
      "epoch": 0.6796497189909816,
      "grad_norm": 0.5619590282440186,
      "learning_rate": 6.408312638870736e-06,
      "loss": 0.0715,
      "step": 10400
    },
    {
      "epoch": 0.6829172657168997,
      "grad_norm": 3.798905372619629,
      "learning_rate": 6.3429617043523726e-06,
      "loss": 0.0833,
      "step": 10450
    },
    {
      "epoch": 0.6861848124428179,
      "grad_norm": 1.048912763595581,
      "learning_rate": 6.277610769834009e-06,
      "loss": 0.0855,
      "step": 10500
    },
    {
      "epoch": 0.6894523591687362,
      "grad_norm": 5.388522624969482,
      "learning_rate": 6.212259835315646e-06,
      "loss": 0.0813,
      "step": 10550
    },
    {
      "epoch": 0.6927199058946543,
      "grad_norm": 2.405447244644165,
      "learning_rate": 6.146908900797282e-06,
      "loss": 0.0998,
      "step": 10600
    },
    {
      "epoch": 0.6959874526205725,
      "grad_norm": 4.076819896697998,
      "learning_rate": 6.081557966278918e-06,
      "loss": 0.0768,
      "step": 10650
    },
    {
      "epoch": 0.6992549993464906,
      "grad_norm": 3.993035316467285,
      "learning_rate": 6.016207031760555e-06,
      "loss": 0.1005,
      "step": 10700
    },
    {
      "epoch": 0.7025225460724088,
      "grad_norm": 0.23324590921401978,
      "learning_rate": 5.950856097242192e-06,
      "loss": 0.0721,
      "step": 10750
    },
    {
      "epoch": 0.705790092798327,
      "grad_norm": 4.643177032470703,
      "learning_rate": 5.885505162723827e-06,
      "loss": 0.0626,
      "step": 10800
    },
    {
      "epoch": 0.7090576395242452,
      "grad_norm": 5.274816989898682,
      "learning_rate": 5.820154228205463e-06,
      "loss": 0.104,
      "step": 10850
    },
    {
      "epoch": 0.7123251862501634,
      "grad_norm": 3.581784725189209,
      "learning_rate": 5.7548032936871e-06,
      "loss": 0.0801,
      "step": 10900
    },
    {
      "epoch": 0.7155927329760815,
      "grad_norm": 6.088094711303711,
      "learning_rate": 5.6894523591687366e-06,
      "loss": 0.0802,
      "step": 10950
    },
    {
      "epoch": 0.7188602797019997,
      "grad_norm": 1.0569252967834473,
      "learning_rate": 5.624101424650373e-06,
      "loss": 0.0801,
      "step": 11000
    },
    {
      "epoch": 0.722127826427918,
      "grad_norm": 4.326475620269775,
      "learning_rate": 5.558750490132009e-06,
      "loss": 0.0829,
      "step": 11050
    },
    {
      "epoch": 0.7253953731538361,
      "grad_norm": 2.8862640857696533,
      "learning_rate": 5.493399555613646e-06,
      "loss": 0.0677,
      "step": 11100
    },
    {
      "epoch": 0.7286629198797543,
      "grad_norm": 4.882797718048096,
      "learning_rate": 5.428048621095282e-06,
      "loss": 0.0703,
      "step": 11150
    },
    {
      "epoch": 0.7319304666056725,
      "grad_norm": 3.5869970321655273,
      "learning_rate": 5.362697686576919e-06,
      "loss": 0.0712,
      "step": 11200
    },
    {
      "epoch": 0.7351980133315906,
      "grad_norm": 0.9776871204376221,
      "learning_rate": 5.297346752058556e-06,
      "loss": 0.0882,
      "step": 11250
    },
    {
      "epoch": 0.7384655600575089,
      "grad_norm": 6.44997501373291,
      "learning_rate": 5.231995817540191e-06,
      "loss": 0.0418,
      "step": 11300
    },
    {
      "epoch": 0.741733106783427,
      "grad_norm": 0.5908859372138977,
      "learning_rate": 5.166644883021827e-06,
      "loss": 0.0797,
      "step": 11350
    },
    {
      "epoch": 0.7450006535093452,
      "grad_norm": 5.093639373779297,
      "learning_rate": 5.101293948503464e-06,
      "loss": 0.0669,
      "step": 11400
    },
    {
      "epoch": 0.7482682002352634,
      "grad_norm": 1.8003489971160889,
      "learning_rate": 5.035943013985101e-06,
      "loss": 0.0714,
      "step": 11450
    },
    {
      "epoch": 0.7515357469611815,
      "grad_norm": 4.169514179229736,
      "learning_rate": 4.970592079466736e-06,
      "loss": 0.0721,
      "step": 11500
    },
    {
      "epoch": 0.7548032936870998,
      "grad_norm": 0.9661141633987427,
      "learning_rate": 4.905241144948373e-06,
      "loss": 0.0655,
      "step": 11550
    },
    {
      "epoch": 0.7580708404130179,
      "grad_norm": 5.195662975311279,
      "learning_rate": 4.83989021043001e-06,
      "loss": 0.0882,
      "step": 11600
    },
    {
      "epoch": 0.7613383871389361,
      "grad_norm": 0.8336268663406372,
      "learning_rate": 4.774539275911646e-06,
      "loss": 0.0712,
      "step": 11650
    },
    {
      "epoch": 0.7646059338648543,
      "grad_norm": 9.305597305297852,
      "learning_rate": 4.709188341393282e-06,
      "loss": 0.074,
      "step": 11700
    },
    {
      "epoch": 0.7678734805907724,
      "grad_norm": 0.20260269939899445,
      "learning_rate": 4.643837406874919e-06,
      "loss": 0.0625,
      "step": 11750
    },
    {
      "epoch": 0.7711410273166907,
      "grad_norm": 0.05176518112421036,
      "learning_rate": 4.5784864723565555e-06,
      "loss": 0.0787,
      "step": 11800
    },
    {
      "epoch": 0.7744085740426088,
      "grad_norm": 4.4015727043151855,
      "learning_rate": 4.513135537838191e-06,
      "loss": 0.0828,
      "step": 11850
    },
    {
      "epoch": 0.777676120768527,
      "grad_norm": 2.76017165184021,
      "learning_rate": 4.447784603319828e-06,
      "loss": 0.0877,
      "step": 11900
    },
    {
      "epoch": 0.7809436674944452,
      "grad_norm": 5.2097554206848145,
      "learning_rate": 4.382433668801464e-06,
      "loss": 0.0872,
      "step": 11950
    },
    {
      "epoch": 0.7842112142203633,
      "grad_norm": 1.8348397016525269,
      "learning_rate": 4.3170827342831e-06,
      "loss": 0.0754,
      "step": 12000
    },
    {
      "epoch": 0.7874787609462816,
      "grad_norm": 4.912964820861816,
      "learning_rate": 4.251731799764737e-06,
      "loss": 0.0626,
      "step": 12050
    },
    {
      "epoch": 0.7907463076721997,
      "grad_norm": 5.479509353637695,
      "learning_rate": 4.186380865246374e-06,
      "loss": 0.09,
      "step": 12100
    },
    {
      "epoch": 0.7940138543981179,
      "grad_norm": 4.624061107635498,
      "learning_rate": 4.1210299307280095e-06,
      "loss": 0.0708,
      "step": 12150
    },
    {
      "epoch": 0.7972814011240361,
      "grad_norm": 1.9386987686157227,
      "learning_rate": 4.055678996209646e-06,
      "loss": 0.0764,
      "step": 12200
    },
    {
      "epoch": 0.8005489478499542,
      "grad_norm": 4.430204391479492,
      "learning_rate": 3.990328061691283e-06,
      "loss": 0.0672,
      "step": 12250
    },
    {
      "epoch": 0.8038164945758725,
      "grad_norm": 3.653282642364502,
      "learning_rate": 3.924977127172919e-06,
      "loss": 0.0614,
      "step": 12300
    },
    {
      "epoch": 0.8070840413017906,
      "grad_norm": 8.449915885925293,
      "learning_rate": 3.859626192654555e-06,
      "loss": 0.0915,
      "step": 12350
    },
    {
      "epoch": 0.8103515880277088,
      "grad_norm": 0.2271503210067749,
      "learning_rate": 3.794275258136192e-06,
      "loss": 0.0654,
      "step": 12400
    },
    {
      "epoch": 0.813619134753627,
      "grad_norm": 5.197118282318115,
      "learning_rate": 3.7289243236178278e-06,
      "loss": 0.0629,
      "step": 12450
    },
    {
      "epoch": 0.8168866814795451,
      "grad_norm": 0.49005165696144104,
      "learning_rate": 3.6635733890994644e-06,
      "loss": 0.0744,
      "step": 12500
    },
    {
      "epoch": 0.8201542282054634,
      "grad_norm": 8.730443954467773,
      "learning_rate": 3.5982224545811007e-06,
      "loss": 0.067,
      "step": 12550
    },
    {
      "epoch": 0.8234217749313815,
      "grad_norm": 5.031013488769531,
      "learning_rate": 3.5328715200627373e-06,
      "loss": 0.0816,
      "step": 12600
    },
    {
      "epoch": 0.8266893216572997,
      "grad_norm": 4.6236419677734375,
      "learning_rate": 3.467520585544373e-06,
      "loss": 0.063,
      "step": 12650
    },
    {
      "epoch": 0.8299568683832179,
      "grad_norm": 0.32038506865501404,
      "learning_rate": 3.4021696510260098e-06,
      "loss": 0.0745,
      "step": 12700
    },
    {
      "epoch": 0.833224415109136,
      "grad_norm": 0.17573463916778564,
      "learning_rate": 3.3368187165076464e-06,
      "loss": 0.0714,
      "step": 12750
    },
    {
      "epoch": 0.8364919618350543,
      "grad_norm": 5.85915994644165,
      "learning_rate": 3.2714677819892827e-06,
      "loss": 0.0712,
      "step": 12800
    },
    {
      "epoch": 0.8397595085609724,
      "grad_norm": 4.509843349456787,
      "learning_rate": 3.2061168474709193e-06,
      "loss": 0.0723,
      "step": 12850
    },
    {
      "epoch": 0.8430270552868906,
      "grad_norm": 3.8701162338256836,
      "learning_rate": 3.140765912952555e-06,
      "loss": 0.0592,
      "step": 12900
    },
    {
      "epoch": 0.8462946020128088,
      "grad_norm": 3.989656686782837,
      "learning_rate": 3.0754149784341918e-06,
      "loss": 0.076,
      "step": 12950
    },
    {
      "epoch": 0.8495621487387269,
      "grad_norm": 2.7293550968170166,
      "learning_rate": 3.0100640439158284e-06,
      "loss": 0.0865,
      "step": 13000
    },
    {
      "epoch": 0.8528296954646452,
      "grad_norm": 3.6404497623443604,
      "learning_rate": 2.9447131093974647e-06,
      "loss": 0.0677,
      "step": 13050
    },
    {
      "epoch": 0.8560972421905634,
      "grad_norm": 4.898749828338623,
      "learning_rate": 2.8793621748791013e-06,
      "loss": 0.084,
      "step": 13100
    },
    {
      "epoch": 0.8593647889164815,
      "grad_norm": 2.5227110385894775,
      "learning_rate": 2.814011240360737e-06,
      "loss": 0.0875,
      "step": 13150
    },
    {
      "epoch": 0.8626323356423997,
      "grad_norm": 7.412894248962402,
      "learning_rate": 2.7486603058423738e-06,
      "loss": 0.0716,
      "step": 13200
    },
    {
      "epoch": 0.8658998823683178,
      "grad_norm": 4.6319427490234375,
      "learning_rate": 2.68330937132401e-06,
      "loss": 0.0713,
      "step": 13250
    },
    {
      "epoch": 0.869167429094236,
      "grad_norm": 2.957930326461792,
      "learning_rate": 2.6179584368056467e-06,
      "loss": 0.0747,
      "step": 13300
    },
    {
      "epoch": 0.8724349758201543,
      "grad_norm": 3.4719085693359375,
      "learning_rate": 2.5526075022872833e-06,
      "loss": 0.0516,
      "step": 13350
    },
    {
      "epoch": 0.8757025225460724,
      "grad_norm": 2.590111017227173,
      "learning_rate": 2.487256567768919e-06,
      "loss": 0.0771,
      "step": 13400
    },
    {
      "epoch": 0.8789700692719906,
      "grad_norm": 4.781814098358154,
      "learning_rate": 2.4219056332505554e-06,
      "loss": 0.0584,
      "step": 13450
    },
    {
      "epoch": 0.8822376159979087,
      "grad_norm": 0.8378884792327881,
      "learning_rate": 2.356554698732192e-06,
      "loss": 0.0618,
      "step": 13500
    },
    {
      "epoch": 0.885505162723827,
      "grad_norm": 6.770359992980957,
      "learning_rate": 2.2912037642138287e-06,
      "loss": 0.0669,
      "step": 13550
    },
    {
      "epoch": 0.8887727094497452,
      "grad_norm": 5.462930202484131,
      "learning_rate": 2.225852829695465e-06,
      "loss": 0.0927,
      "step": 13600
    },
    {
      "epoch": 0.8920402561756633,
      "grad_norm": 5.764807224273682,
      "learning_rate": 2.160501895177101e-06,
      "loss": 0.0697,
      "step": 13650
    },
    {
      "epoch": 0.8953078029015815,
      "grad_norm": 2.422614097595215,
      "learning_rate": 2.0951509606587374e-06,
      "loss": 0.0786,
      "step": 13700
    },
    {
      "epoch": 0.8985753496274996,
      "grad_norm": 1.8444793224334717,
      "learning_rate": 2.029800026140374e-06,
      "loss": 0.0662,
      "step": 13750
    },
    {
      "epoch": 0.9018428963534179,
      "grad_norm": 5.52435302734375,
      "learning_rate": 1.9644490916220107e-06,
      "loss": 0.067,
      "step": 13800
    },
    {
      "epoch": 0.9051104430793361,
      "grad_norm": 4.160999298095703,
      "learning_rate": 1.899098157103647e-06,
      "loss": 0.072,
      "step": 13850
    },
    {
      "epoch": 0.9083779898052542,
      "grad_norm": 6.021420478820801,
      "learning_rate": 1.8337472225852831e-06,
      "loss": 0.0679,
      "step": 13900
    },
    {
      "epoch": 0.9116455365311724,
      "grad_norm": 3.0654640197753906,
      "learning_rate": 1.7683962880669196e-06,
      "loss": 0.0702,
      "step": 13950
    },
    {
      "epoch": 0.9149130832570905,
      "grad_norm": 4.163793087005615,
      "learning_rate": 1.7030453535485558e-06,
      "loss": 0.0901,
      "step": 14000
    },
    {
      "epoch": 0.9181806299830088,
      "grad_norm": 0.5790098905563354,
      "learning_rate": 1.6376944190301923e-06,
      "loss": 0.0721,
      "step": 14050
    },
    {
      "epoch": 0.921448176708927,
      "grad_norm": 2.8824095726013184,
      "learning_rate": 1.5723434845118287e-06,
      "loss": 0.0669,
      "step": 14100
    },
    {
      "epoch": 0.9247157234348451,
      "grad_norm": 3.465773344039917,
      "learning_rate": 1.5069925499934651e-06,
      "loss": 0.0805,
      "step": 14150
    },
    {
      "epoch": 0.9279832701607633,
      "grad_norm": 5.2826762199401855,
      "learning_rate": 1.4416416154751014e-06,
      "loss": 0.0782,
      "step": 14200
    },
    {
      "epoch": 0.9312508168866814,
      "grad_norm": 2.8997960090637207,
      "learning_rate": 1.3762906809567378e-06,
      "loss": 0.0898,
      "step": 14250
    },
    {
      "epoch": 0.9345183636125997,
      "grad_norm": 2.912569761276245,
      "learning_rate": 1.310939746438374e-06,
      "loss": 0.0648,
      "step": 14300
    },
    {
      "epoch": 0.9377859103385179,
      "grad_norm": 0.6634737849235535,
      "learning_rate": 1.2455888119200105e-06,
      "loss": 0.0795,
      "step": 14350
    },
    {
      "epoch": 0.941053457064436,
      "grad_norm": 9.534781455993652,
      "learning_rate": 1.180237877401647e-06,
      "loss": 0.0626,
      "step": 14400
    },
    {
      "epoch": 0.9443210037903542,
      "grad_norm": 6.973989486694336,
      "learning_rate": 1.1148869428832832e-06,
      "loss": 0.0647,
      "step": 14450
    },
    {
      "epoch": 0.9475885505162723,
      "grad_norm": 7.4965643882751465,
      "learning_rate": 1.0495360083649198e-06,
      "loss": 0.0582,
      "step": 14500
    },
    {
      "epoch": 0.9508560972421906,
      "grad_norm": 0.7228202223777771,
      "learning_rate": 9.84185073846556e-07,
      "loss": 0.0564,
      "step": 14550
    },
    {
      "epoch": 0.9541236439681088,
      "grad_norm": 2.816986560821533,
      "learning_rate": 9.188341393281924e-07,
      "loss": 0.0644,
      "step": 14600
    },
    {
      "epoch": 0.9573911906940269,
      "grad_norm": 0.929398775100708,
      "learning_rate": 8.53483204809829e-07,
      "loss": 0.0748,
      "step": 14650
    },
    {
      "epoch": 0.9606587374199451,
      "grad_norm": 1.115792155265808,
      "learning_rate": 7.881322702914653e-07,
      "loss": 0.0574,
      "step": 14700
    },
    {
      "epoch": 0.9639262841458632,
      "grad_norm": 1.1407450437545776,
      "learning_rate": 7.227813357731016e-07,
      "loss": 0.0747,
      "step": 14750
    },
    {
      "epoch": 0.9671938308717815,
      "grad_norm": 0.23223240673542023,
      "learning_rate": 6.574304012547381e-07,
      "loss": 0.0659,
      "step": 14800
    },
    {
      "epoch": 0.9704613775976997,
      "grad_norm": 5.529504776000977,
      "learning_rate": 5.920794667363744e-07,
      "loss": 0.0876,
      "step": 14850
    },
    {
      "epoch": 0.9737289243236178,
      "grad_norm": 0.18012994527816772,
      "learning_rate": 5.267285322180107e-07,
      "loss": 0.0593,
      "step": 14900
    },
    {
      "epoch": 0.976996471049536,
      "grad_norm": 6.837048530578613,
      "learning_rate": 4.6137759769964713e-07,
      "loss": 0.0658,
      "step": 14950
    },
    {
      "epoch": 0.9802640177754542,
      "grad_norm": 2.6385550498962402,
      "learning_rate": 3.960266631812835e-07,
      "loss": 0.0818,
      "step": 15000
    },
    {
      "epoch": 0.9835315645013724,
      "grad_norm": 5.1733574867248535,
      "learning_rate": 3.3067572866291986e-07,
      "loss": 0.0515,
      "step": 15050
    },
    {
      "epoch": 0.9867991112272906,
      "grad_norm": 7.224614143371582,
      "learning_rate": 2.653247941445563e-07,
      "loss": 0.0667,
      "step": 15100
    },
    {
      "epoch": 0.9900666579532087,
      "grad_norm": 0.201846182346344,
      "learning_rate": 1.9997385962619267e-07,
      "loss": 0.0801,
      "step": 15150
    },
    {
      "epoch": 0.9933342046791269,
      "grad_norm": 7.544262886047363,
      "learning_rate": 1.3462292510782906e-07,
      "loss": 0.0639,
      "step": 15200
    },
    {
      "epoch": 0.9966017514050451,
      "grad_norm": 4.809071063995361,
      "learning_rate": 6.927199058946544e-08,
      "loss": 0.0805,
      "step": 15250
    },
    {
      "epoch": 0.9998692981309633,
      "grad_norm": 0.22226911783218384,
      "learning_rate": 3.921056071101817e-09,
      "loss": 0.0577,
      "step": 15300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9729720564297342,
      "eval_f1": 0.9729436127236311,
      "eval_loss": 0.08492294698953629,
      "eval_runtime": 93.2913,
      "eval_samples_per_second": 632.17,
      "eval_steps_per_second": 19.755,
      "step": 15302
    }
  ],
  "logging_steps": 50,
  "max_steps": 15302,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.220800188946432e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
